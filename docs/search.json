[
  {
    "objectID": "2_2_posit-cloud.html",
    "href": "2_2_posit-cloud.html",
    "title": "Posit Cloud",
    "section": "",
    "text": "We’ve encountered a few different names at this point. To clarify the ecosystem:\n\nR is a coding language for statistics and data analysis\nRStudio is a software interface for writing and running R code\nPosit is the name of the company that develops RStudio (formerly called RStudio, Inc.)\nposit.cloud is the browser-based version of RStudio, hosted and managed by Posit\n\nAs we’ve seen, you can install R and RStudio on your own computer for free and do things that way, but using posit.cloud simplifies things immensely when it comes to using R in the classroom. It substantially lowers the barrier to entry; frees us to focus on statistical fluency rather than tool fluency.\n\n\n\n\n\n\n\n\n\n\n\n\nFeature\nLocal RStudio\nPosit Cloud\n\n\n\n\nSetup required\nYes — install R + RStudio\nNone — runs in browser\n\n\nPlatform consistency\nVaries by OS (Mac/Win/etc)\nIdentical for all students\n\n\nFile storage\nOn user’s machine\nIn the cloud — per project\n\n\nPackage installation\nManual per machine\nBundled with assignments\n\n\nInstructor access to work\nOnly if student sends files\nInstructor can directly view projects\n\n\nCollaboration\nTricky / manual\nEasy via shared projects\n\n\n\n\n\n\n\nMust be online: offline work not possible\nProjects are somewhat slow to launch, even on fast internet (but once it’s up and running the experience is virtually identical to local installation)\nLimited compute resources: not great for giant datasets, heavy ML or large simulations\nFree tier may throttle or limit use if you go over project/hour quotas\n\n\n\n\nNo cost to students. Potentially cost to instructor/department.\n\n\n\n\n\n\n\n\n\n\nTier:\nFree\nInstructor (pay per compute hour)\nInstructor (pay per student)\n\n\n\n\nCost\n$0\n$15/month up to 300 compute hours, $0.10 per hour over 300\n$15 per instructor + $5 per student per month\n\n\nCompute hours included\n25 (once you reach the cap, you can no longer open or create projects during your current month)\n300 (pay for overage)\nUnlimited\n\n\nShared Spaces\n1 shared space with up to 5 members and 10 content items in the space\nUnlimited\nUnlimited\n\n\nProjects\n25\nUnlimited\nUnlimited\n\n\n\n\n\n\n\n\n\n\n\nProjects in the cloud function much like local R Projects: they provide a somewhat self-contained environment for collecting together R files, data files, etc relating to a particular project. However, Projects in the cloud are even more encapsulated than local Projects.\nLocally, all your projects will be able to make use of any external packages installed on your system. In the cloud, each project essentially runs on its own system; packages must be installed in every new Project. A cloud-based Project also has its own filesystem; data files stored in one project in the cloud cannot be accessed in another Project; the file must be manually uploaded to each Project.\nAny cloud Project in Your Workspace can be shared with All Posit Cloud users. When you share the link, a user can click into it. They will initially be working with a temporary copy of the project. They can click a button to save their own permanent copy. Note that sharing a Project this way does not allow other users to modify your copy of the Project in any way; they will always be working on their own copy.\n\n\n\nAny posit.cloud Project in a Space you have created (but not in Your Workspace) can be made an Assignment. This has some advantages over just sharing Projects in the way described above. Primarily, as soon as a user opens the Assignment, the system creates a copy for them in the Space. The user does not have to click manually to save their own version.\n\n\n\nCreate a Space for your course (potentially a new Space each semester)\nCreate a Project with all required files and packages\nConvert it to an Assignment\nInvite students to join the Space\nShare the Assignment link with students (or they can see it listed in the Space)\nEach student gets their own private copy when they click into it\n\n\n\n\n\nView their copies\nOpen their Projects directly\nRun/debug their code\nLeave feedback in-line\n\n\n\n\n\nNo setup required by students\nNo broken paths, version mismatches, or install errors\nPackages installed in your source version will be already installed in students’ copies\nSee all student work in one place\nEffortless sharing of starter code, datasets, templates",
    "crumbs": [
      "Day 2: Teaching with R",
      "Posit Cloud"
    ]
  },
  {
    "objectID": "2_2_posit-cloud.html#whats-what",
    "href": "2_2_posit-cloud.html#whats-what",
    "title": "Posit Cloud",
    "section": "",
    "text": "We’ve encountered a few different names at this point. To clarify the ecosystem:\n\nR is a coding language for statistics and data analysis\nRStudio is a software interface for writing and running R code\nPosit is the name of the company that develops RStudio (formerly called RStudio, Inc.)\nposit.cloud is the browser-based version of RStudio, hosted and managed by Posit\n\nAs we’ve seen, you can install R and RStudio on your own computer for free and do things that way, but using posit.cloud simplifies things immensely when it comes to using R in the classroom. It substantially lowers the barrier to entry; frees us to focus on statistical fluency rather than tool fluency.",
    "crumbs": [
      "Day 2: Teaching with R",
      "Posit Cloud"
    ]
  },
  {
    "objectID": "2_2_posit-cloud.html#cloud-vs-local-main-differences",
    "href": "2_2_posit-cloud.html#cloud-vs-local-main-differences",
    "title": "Posit Cloud",
    "section": "",
    "text": "Feature\nLocal RStudio\nPosit Cloud\n\n\n\n\nSetup required\nYes — install R + RStudio\nNone — runs in browser\n\n\nPlatform consistency\nVaries by OS (Mac/Win/etc)\nIdentical for all students\n\n\nFile storage\nOn user’s machine\nIn the cloud — per project\n\n\nPackage installation\nManual per machine\nBundled with assignments\n\n\nInstructor access to work\nOnly if student sends files\nInstructor can directly view projects\n\n\nCollaboration\nTricky / manual\nEasy via shared projects\n\n\n\n\n\n\n\nMust be online: offline work not possible\nProjects are somewhat slow to launch, even on fast internet (but once it’s up and running the experience is virtually identical to local installation)\nLimited compute resources: not great for giant datasets, heavy ML or large simulations\nFree tier may throttle or limit use if you go over project/hour quotas\n\n\n\n\nNo cost to students. Potentially cost to instructor/department.\n\n\n\n\n\n\n\n\n\n\nTier:\nFree\nInstructor (pay per compute hour)\nInstructor (pay per student)\n\n\n\n\nCost\n$0\n$15/month up to 300 compute hours, $0.10 per hour over 300\n$15 per instructor + $5 per student per month\n\n\nCompute hours included\n25 (once you reach the cap, you can no longer open or create projects during your current month)\n300 (pay for overage)\nUnlimited\n\n\nShared Spaces\n1 shared space with up to 5 members and 10 content items in the space\nUnlimited\nUnlimited\n\n\nProjects\n25\nUnlimited\nUnlimited",
    "crumbs": [
      "Day 2: Teaching with R",
      "Posit Cloud"
    ]
  },
  {
    "objectID": "2_2_posit-cloud.html#projects-and-assignments",
    "href": "2_2_posit-cloud.html#projects-and-assignments",
    "title": "Posit Cloud",
    "section": "",
    "text": "Projects in the cloud function much like local R Projects: they provide a somewhat self-contained environment for collecting together R files, data files, etc relating to a particular project. However, Projects in the cloud are even more encapsulated than local Projects.\nLocally, all your projects will be able to make use of any external packages installed on your system. In the cloud, each project essentially runs on its own system; packages must be installed in every new Project. A cloud-based Project also has its own filesystem; data files stored in one project in the cloud cannot be accessed in another Project; the file must be manually uploaded to each Project.\nAny cloud Project in Your Workspace can be shared with All Posit Cloud users. When you share the link, a user can click into it. They will initially be working with a temporary copy of the project. They can click a button to save their own permanent copy. Note that sharing a Project this way does not allow other users to modify your copy of the Project in any way; they will always be working on their own copy.\n\n\n\nAny posit.cloud Project in a Space you have created (but not in Your Workspace) can be made an Assignment. This has some advantages over just sharing Projects in the way described above. Primarily, as soon as a user opens the Assignment, the system creates a copy for them in the Space. The user does not have to click manually to save their own version.\n\n\n\nCreate a Space for your course (potentially a new Space each semester)\nCreate a Project with all required files and packages\nConvert it to an Assignment\nInvite students to join the Space\nShare the Assignment link with students (or they can see it listed in the Space)\nEach student gets their own private copy when they click into it\n\n\n\n\n\nView their copies\nOpen their Projects directly\nRun/debug their code\nLeave feedback in-line\n\n\n\n\n\nNo setup required by students\nNo broken paths, version mismatches, or install errors\nPackages installed in your source version will be already installed in students’ copies\nSee all student work in one place\nEffortless sharing of starter code, datasets, templates",
    "crumbs": [
      "Day 2: Teaching with R",
      "Posit Cloud"
    ]
  },
  {
    "objectID": "2_2_posit-cloud_presentation.html#whats-what",
    "href": "2_2_posit-cloud_presentation.html#whats-what",
    "title": "R Faculty Workshop",
    "section": "What’s what",
    "text": "What’s what\n\nR is a coding language for statistics and data analysis\nRStudio is a software interface for writing and running R code\nPosit is the name of the company that develops RStudio (formerly called RStudio, Inc.)\nposit.cloud is the browser-based version of RStudio, hosted and managed by Posit"
  },
  {
    "objectID": "2_2_posit-cloud_presentation.html#cloud-vs-local-main-differences",
    "href": "2_2_posit-cloud_presentation.html#cloud-vs-local-main-differences",
    "title": "R Faculty Workshop",
    "section": "Cloud vs local: main differences",
    "text": "Cloud vs local: main differences\n\n\n\n\n\n\n\n\n\nFeature\nLocal RStudio\nPosit Cloud\n\n\n\n\nSetup required\nYes — install R + RStudio\nNone — runs in browser\n\n\nPlatform consistency\nVaries by OS (Mac/Win/etc)\nIdentical for all students\n\n\nFile storage\nOn user’s machine\nIn the cloud — per project\n\n\nPackage installation\nManual per machine\nBundled with assignments\n\n\nInstructor access to work\nOnly if student sends files\nInstructor can directly view projects\n\n\nCollaboration\nTricky / manual\nEasy via shared projects"
  },
  {
    "objectID": "2_2_posit-cloud_presentation.html#projects-and-assignments",
    "href": "2_2_posit-cloud_presentation.html#projects-and-assignments",
    "title": "R Faculty Workshop",
    "section": "Projects and assignments",
    "text": "Projects and assignments"
  },
  {
    "objectID": "2_4_course-materials.html",
    "href": "2_4_course-materials.html",
    "title": "Course Materials",
    "section": "",
    "text": "PSYC BC1101 Materials\n\n\n\nMy Statistics materials are online here:\nhttps://robbrotherton.github.io/bc1101/\n\n\nStructure of recitation:\n\nI talk through a topic hands-on for around 10 or 15 minutes, noting the new functions and ideas students will encounter, how they map on to content we covered in lectures, and flagging up potential sticking points in advance.\nThen I let students continue working. I encourage them to work independently, to collaborate, and/or to seek help from me or their TA as and when the need arises.\nThe students are working in a single Quarto document for each problem set. The doc contains Instructional blocks and questions with space for students to answer using text and/or code. Instructions contain hints that show the general structure of the solution; students adapt those hints to get the final solution.\nFeedback: Following submission of their attempt, students receive full, detailed feedback noting both what they did well and what they could have done differently.\n\n\n\n\n\n\n\n\n\n\nSocial lab materials\n\n\n\nMy Social lab manual is online here:\nhttps://robbrotherton.github.io/bc2137/\n\n\nFor my labs, I have put my materials together as a Quarto website. Every lab session has its own page (including the syllabus on the site’s home page).\nIn conjunction with that, I have a posit.cloud Project containing the required data files, and report templates.",
    "crumbs": [
      "Day 2: Teaching with R",
      "Course Materials"
    ]
  },
  {
    "objectID": "2_4_course-materials.html#statistics",
    "href": "2_4_course-materials.html#statistics",
    "title": "Course Materials",
    "section": "",
    "text": "PSYC BC1101 Materials\n\n\n\nMy Statistics materials are online here:\nhttps://robbrotherton.github.io/bc1101/\n\n\nStructure of recitation:\n\nI talk through a topic hands-on for around 10 or 15 minutes, noting the new functions and ideas students will encounter, how they map on to content we covered in lectures, and flagging up potential sticking points in advance.\nThen I let students continue working. I encourage them to work independently, to collaborate, and/or to seek help from me or their TA as and when the need arises.\nThe students are working in a single Quarto document for each problem set. The doc contains Instructional blocks and questions with space for students to answer using text and/or code. Instructions contain hints that show the general structure of the solution; students adapt those hints to get the final solution.\nFeedback: Following submission of their attempt, students receive full, detailed feedback noting both what they did well and what they could have done differently.",
    "crumbs": [
      "Day 2: Teaching with R",
      "Course Materials"
    ]
  },
  {
    "objectID": "2_4_course-materials.html#labs",
    "href": "2_4_course-materials.html#labs",
    "title": "Course Materials",
    "section": "",
    "text": "Social lab materials\n\n\n\nMy Social lab manual is online here:\nhttps://robbrotherton.github.io/bc2137/\n\n\nFor my labs, I have put my materials together as a Quarto website. Every lab session has its own page (including the syllabus on the site’s home page).\nIn conjunction with that, I have a posit.cloud Project containing the required data files, and report templates.",
    "crumbs": [
      "Day 2: Teaching with R",
      "Course Materials"
    ]
  },
  {
    "objectID": "2_4_course-materials_presentation.html#statistics",
    "href": "2_4_course-materials_presentation.html#statistics",
    "title": "R Faculty Workshop",
    "section": "Statistics",
    "text": "Statistics\n\n\n\n\n\n\nPSYC BC1101 Materials\n\n\nMy Statistics materials are online here:\nhttps://robbrotherton.github.io/bc1101/\n\n\n\nStructure of recitation:\n\nI talk through a topic hands-on for around 10 or 15 minutes, noting the new functions and ideas students will encounter, how they map on to content we covered in lectures, and flagging up potential sticking points in advance.\nThen I let students continue working. I encourage them to work independently, to collaborate, and/or to seek help from me or their TA as and when the need arises.\nThe students are working in a single Quarto document for each problem set. The doc contains Instructional blocks and questions with space for students to answer using text and/or code. Instructions contain hints that show the general structure of the solution; students adapt those hints to get the final solution.\nFeedback: Following submission of their attempt, students receive full, detailed feedback noting both what they did well and what they could have done differently."
  },
  {
    "objectID": "2_4_course-materials_presentation.html#labs",
    "href": "2_4_course-materials_presentation.html#labs",
    "title": "R Faculty Workshop",
    "section": "Labs",
    "text": "Labs\n\n\n\n\n\n\nSocial lab materials\n\n\nMy Social lab manual is online here:\nhttps://robbrotherton.github.io/bc2137/\n\n\n\nFor my labs, I have put my materials together as a Quarto website. Every lab session has its own page (including the syllabus on the site’s home page).\nIn conjunction with that, I have a posit.cloud Project containing the required data files, and report templates."
  },
  {
    "objectID": "2_1_general-approach.html",
    "href": "2_1_general-approach.html",
    "title": "General thoughts on teaching with R",
    "section": "",
    "text": "In this session we’ll start working in Posit Cloud. I’ve created a ‘Space’ for this workshop. You can join using this link:\nhttps://posit.cloud/spaces/647833/join?access_code=d044OrLrWY83pbYiQXdsnuYbxO1_vDN_rN1Q7pYx\nI’ll link you to the actual R materials in due course.\n\n\n\n\nposit.cloud/spaces/647833/content/10308914\n\n\n\n\nSkill Development: Proficiency in R is increasingly sought after in both academic and industry settings, enhancing students’ career prospects. See : https://r4stats.com/articles/popularity/\nReproducibility: R promotes transparent and reproducible research practices, aligning with open science principles.\nCost-Effectiveness: R is free and open-source, making it accessible to all students regardless of financial resources.\nConceptual Understanding: Coding statistical procedures reinforces comprehension of underlying concepts. For example, writing functions to compute z-scores or simulate sampling distributions deepens understanding.\n\nRequiring students to learn both statistical concepts (or research methods or whatever) and coding is a lot to ask in a single semester. Setting expectations and stating goals can help students see learning R as worthwhile from the outset.\n\n\n\nLearning R can be challenging, especially for students new to programming. In R, there is often more than one way to do things. Some approaches may be more effective and straightforward than others, but there is value in the process of discovery. Making mistakes and learning how to resolve them is a crucial part of learning to code. In setting coding assignments, I want to emphasize that the value is in the effort, even if it does not immediately produce the ideal outcome.\nThe only way to write good code is to write tons of shitty code first. Feeling shame about bad code stops you from getting to good code— Hadley Wickham (@hadleywickham) April 17, 2015\nTo foster a supportive learning environment:\n\nEffort-Based Grading: Assign grades based on the completeness and sincerity of attempts rather than correctness. This encourages experimentation and reduces anxiety.\nFeedback-Oriented: Provide constructive feedback to guide improvement, focusing on the learning process over the final product.\n\nMy grading scheme:\n\n0 points: No submission\n1 point: Incomplete attempt\n2 point: Complete, valid attempt\n\nThat’s it. Every student gets full credit for a valid attempt. Even if every answer is wrong, they get full credit for the effort. It is entirely possible for every student to get full credit for the coding assignments across the semester, even if they never get a single correct answer–as long as they try. Of course, generally students will learn from their mistakes and improve along the way.\nThe drawback to this is that it does not differentiate the students who put in great effort, going above and beyond expectations, from those who simply meet the minimum requirements of the assignments. I feel that is a worthwhile trade-off, especially since such efforts can be rewarded as part of a participation grade, for example.\n\n\n\nStudents often encounter specific hurdles when learning R:\n\nAnnoying technical problems: Forgetting to install or load necessary packages leads to errors.\nSyntax Errors: Missing commas, parentheses, or quotation marks are common. Encourage the use of RStudio’s syntax highlighting and error messages to identify issues.\nUnderstanding Data Structures: Differentiating between vectors, data frames, and lists can be confusing. Use analogies and visual aids to clarify these concepts.\nAnnoying technical problems: Forgetting to install or load necessary packages leads to errors.\nFunction Arguments: Misunderstanding default arguments or the order of parameters can cause unexpected results. Demonstrate how to find and read function documentation effectively.\n\nTo address these challenges:\n\nIncremental Learning: Introduce concepts gradually, building upon previous knowledge.\nActive Practice: Incorporate hands-on exercises that allow students to apply new skills immediately.\n\n\n\n\nOne of the nice things about R is that many academic users have developed great teaching materials and made them available for free. A few examples:\n\nDanielle Navarro (2019) Learning Statistics with R\nMine Çetinkaya-Rundel and Johanna Hardin (2022) Modern Statistical Methods for Psychology\nRussell A. Poldrack (2018) Statistical Thinking for the 21st Century\n\n\n\n\nIn its latest version RStudio has Github Copilot, an LLM interface, built-in. It suggests code that might come after what you have typed so far. You can even just type a comment about what you would like to achieve, and Copilot will suggest code. Here, I typed the comment and the function name, and Copilot completed the function body.\n\n# a function to compute the sum of squared deviations\nsum_squares &lt;- function(x) {\n  n &lt;- length(x)\n  mean_x &lt;- mean(x)\n  sum_sq_dev &lt;- sum((x - mean_x)^2)\n  return(sum_sq_dev)\n}\n\nsum_squares(c(1, 2, 3, 4, 5))\n\n[1] 10",
    "crumbs": [
      "Day 2: Teaching with R",
      "General thoughts on teaching with R"
    ]
  },
  {
    "objectID": "2_1_general-approach.html#start-with-something-cool",
    "href": "2_1_general-approach.html#start-with-something-cool",
    "title": "General thoughts on teaching with R",
    "section": "",
    "text": "posit.cloud/spaces/647833/content/10308914",
    "crumbs": [
      "Day 2: Teaching with R",
      "General thoughts on teaching with R"
    ]
  },
  {
    "objectID": "2_1_general-approach.html#justify-using-r",
    "href": "2_1_general-approach.html#justify-using-r",
    "title": "General thoughts on teaching with R",
    "section": "",
    "text": "Skill Development: Proficiency in R is increasingly sought after in both academic and industry settings, enhancing students’ career prospects. See : https://r4stats.com/articles/popularity/\nReproducibility: R promotes transparent and reproducible research practices, aligning with open science principles.\nCost-Effectiveness: R is free and open-source, making it accessible to all students regardless of financial resources.\nConceptual Understanding: Coding statistical procedures reinforces comprehension of underlying concepts. For example, writing functions to compute z-scores or simulate sampling distributions deepens understanding.\n\nRequiring students to learn both statistical concepts (or research methods or whatever) and coding is a lot to ask in a single semester. Setting expectations and stating goals can help students see learning R as worthwhile from the outset.",
    "crumbs": [
      "Day 2: Teaching with R",
      "General thoughts on teaching with R"
    ]
  },
  {
    "objectID": "2_1_general-approach.html#grading",
    "href": "2_1_general-approach.html#grading",
    "title": "General thoughts on teaching with R",
    "section": "",
    "text": "Learning R can be challenging, especially for students new to programming. In R, there is often more than one way to do things. Some approaches may be more effective and straightforward than others, but there is value in the process of discovery. Making mistakes and learning how to resolve them is a crucial part of learning to code. In setting coding assignments, I want to emphasize that the value is in the effort, even if it does not immediately produce the ideal outcome.\nThe only way to write good code is to write tons of shitty code first. Feeling shame about bad code stops you from getting to good code— Hadley Wickham (@hadleywickham) April 17, 2015\nTo foster a supportive learning environment:\n\nEffort-Based Grading: Assign grades based on the completeness and sincerity of attempts rather than correctness. This encourages experimentation and reduces anxiety.\nFeedback-Oriented: Provide constructive feedback to guide improvement, focusing on the learning process over the final product.\n\nMy grading scheme:\n\n0 points: No submission\n1 point: Incomplete attempt\n2 point: Complete, valid attempt\n\nThat’s it. Every student gets full credit for a valid attempt. Even if every answer is wrong, they get full credit for the effort. It is entirely possible for every student to get full credit for the coding assignments across the semester, even if they never get a single correct answer–as long as they try. Of course, generally students will learn from their mistakes and improve along the way.\nThe drawback to this is that it does not differentiate the students who put in great effort, going above and beyond expectations, from those who simply meet the minimum requirements of the assignments. I feel that is a worthwhile trade-off, especially since such efforts can be rewarded as part of a participation grade, for example.",
    "crumbs": [
      "Day 2: Teaching with R",
      "General thoughts on teaching with R"
    ]
  },
  {
    "objectID": "2_1_general-approach.html#most-common-problems",
    "href": "2_1_general-approach.html#most-common-problems",
    "title": "General thoughts on teaching with R",
    "section": "",
    "text": "Students often encounter specific hurdles when learning R:\n\nAnnoying technical problems: Forgetting to install or load necessary packages leads to errors.\nSyntax Errors: Missing commas, parentheses, or quotation marks are common. Encourage the use of RStudio’s syntax highlighting and error messages to identify issues.\nUnderstanding Data Structures: Differentiating between vectors, data frames, and lists can be confusing. Use analogies and visual aids to clarify these concepts.\nAnnoying technical problems: Forgetting to install or load necessary packages leads to errors.\nFunction Arguments: Misunderstanding default arguments or the order of parameters can cause unexpected results. Demonstrate how to find and read function documentation effectively.\n\nTo address these challenges:\n\nIncremental Learning: Introduce concepts gradually, building upon previous knowledge.\nActive Practice: Incorporate hands-on exercises that allow students to apply new skills immediately.",
    "crumbs": [
      "Day 2: Teaching with R",
      "General thoughts on teaching with R"
    ]
  },
  {
    "objectID": "2_1_general-approach.html#additional-resources",
    "href": "2_1_general-approach.html#additional-resources",
    "title": "General thoughts on teaching with R",
    "section": "",
    "text": "One of the nice things about R is that many academic users have developed great teaching materials and made them available for free. A few examples:\n\nDanielle Navarro (2019) Learning Statistics with R\nMine Çetinkaya-Rundel and Johanna Hardin (2022) Modern Statistical Methods for Psychology\nRussell A. Poldrack (2018) Statistical Thinking for the 21st Century",
    "crumbs": [
      "Day 2: Teaching with R",
      "General thoughts on teaching with R"
    ]
  },
  {
    "objectID": "2_1_general-approach.html#generative-ai",
    "href": "2_1_general-approach.html#generative-ai",
    "title": "General thoughts on teaching with R",
    "section": "",
    "text": "In its latest version RStudio has Github Copilot, an LLM interface, built-in. It suggests code that might come after what you have typed so far. You can even just type a comment about what you would like to achieve, and Copilot will suggest code. Here, I typed the comment and the function name, and Copilot completed the function body.\n\n# a function to compute the sum of squared deviations\nsum_squares &lt;- function(x) {\n  n &lt;- length(x)\n  mean_x &lt;- mean(x)\n  sum_sq_dev &lt;- sum((x - mean_x)^2)\n  return(sum_sq_dev)\n}\n\nsum_squares(c(1, 2, 3, 4, 5))\n\n[1] 10",
    "crumbs": [
      "Day 2: Teaching with R",
      "General thoughts on teaching with R"
    ]
  },
  {
    "objectID": "2_1_general-approach_presentation.html#start-with-something-cool",
    "href": "2_1_general-approach_presentation.html#start-with-something-cool",
    "title": "R Faculty Workshop",
    "section": "Start with something cool",
    "text": "Start with something cool\nposit.cloud/spaces/647833/content/10308914"
  },
  {
    "objectID": "2_1_general-approach_presentation.html#justify-using-r",
    "href": "2_1_general-approach_presentation.html#justify-using-r",
    "title": "R Faculty Workshop",
    "section": "Justify using R",
    "text": "Justify using R\n\nSkill Development: Proficiency in R is increasingly sought after in both academic and industry settings, enhancing students’ career prospects. See : https://r4stats.com/articles/popularity/\nReproducibility: R promotes transparent and reproducible research practices, aligning with open science principles.\nCost-Effectiveness: R is free and open-source, making it accessible to all students regardless of financial resources.\nConceptual Understanding: Coding statistical procedures reinforces comprehension of underlying concepts. For example, writing functions to compute z-scores or simulate sampling distributions deepens understanding.\n\nRequiring students to learn both statistical concepts (or research methods or whatever) and coding is a lot to ask in a single semester. Setting expectations and stating goals can help students see learning R as worthwhile from the outset."
  },
  {
    "objectID": "2_1_general-approach_presentation.html#grading",
    "href": "2_1_general-approach_presentation.html#grading",
    "title": "R Faculty Workshop",
    "section": "Grading",
    "text": "Grading\nThe only way to write good code is to write tons of shitty code first. Feeling shame about bad code stops you from getting to good code— Hadley Wickham (@hadleywickham) April 17, 2015\nTo foster a supportive learning environment:\n\nEffort-Based Grading: Assign grades based on the completeness and sincerity of attempts rather than correctness. This encourages experimentation and reduces anxiety.\nFeedback-Oriented: Provide constructive feedback to guide improvement, focusing on the learning process over the final product.\n\nMy grading scheme:\n\n0 points: No submission\n1 point: Incomplete attempt\n2 point: Complete, valid attempt"
  },
  {
    "objectID": "2_1_general-approach_presentation.html#most-common-problems",
    "href": "2_1_general-approach_presentation.html#most-common-problems",
    "title": "R Faculty Workshop",
    "section": "Most common problems",
    "text": "Most common problems\nStudents often encounter specific hurdles when learning R:\n\nAnnoying technical problems: Forgetting to install or load necessary packages leads to errors.\nSyntax Errors: Missing commas, parentheses, or quotation marks are common. Encourage the use of RStudio’s syntax highlighting and error messages to identify issues.\nUnderstanding Data Structures: Differentiating between vectors, data frames, and lists can be confusing. Use analogies and visual aids to clarify these concepts.\nAnnoying technical problems: Forgetting to install or load necessary packages leads to errors.\nFunction Arguments: Misunderstanding default arguments or the order of parameters can cause unexpected results. Demonstrate how to find and read function documentation effectively.\n\nTo address these challenges:\n\nIncremental Learning: Introduce concepts gradually, building upon previous knowledge.\nActive Practice: Incorporate hands-on exercises that allow students to apply new skills immediately."
  },
  {
    "objectID": "2_1_general-approach_presentation.html#additional-resources",
    "href": "2_1_general-approach_presentation.html#additional-resources",
    "title": "R Faculty Workshop",
    "section": "Additional resources",
    "text": "Additional resources\nOne of the nice things about R is that many academic users have developed great teaching materials and made them available for free. A few examples:\n\nDanielle Navarro (2019) Learning Statistics with R\nMine Çetinkaya-Rundel and Johanna Hardin (2022) Modern Statistical Methods for Psychology\nRussell A. Poldrack (2018) Statistical Thinking for the 21st Century"
  },
  {
    "objectID": "2_1_general-approach_presentation.html#generative-ai",
    "href": "2_1_general-approach_presentation.html#generative-ai",
    "title": "R Faculty Workshop",
    "section": "Generative AI",
    "text": "Generative AI\nIn its latest version RStudio has Github Copilot, an LLM interface, built-in. It suggests code that might come after what you have typed so far. You can even just type a comment about what you would like to achieve, and Copilot will suggest code. Here, I typed the comment and the function name, and Copilot completed the function body.\n\n# a function to compute the sum of squared deviations\nsum_squares &lt;- function(x) {\n  n &lt;- length(x)\n  mean_x &lt;- mean(x)\n  sum_sq_dev &lt;- sum((x - mean_x)^2)\n  return(sum_sq_dev)\n}\n\nsum_squares(c(1, 2, 3, 4, 5))\n\n[1] 10"
  },
  {
    "objectID": "1_4_other-things.html",
    "href": "1_4_other-things.html",
    "title": "Common causes of confusion",
    "section": "",
    "text": "Resources\n\n\n\nDownload this file to accompany this section:\n\n causes-of-confusion.R\n\nAfter you save it, double click it and it should open in the Editor pane in RStudio.\n\n\n\n\n\n\nAny small typo in a name will case R to throw an error.\n\nnumbers &lt;- c(1, 2, 3, 4, 5)\n\nnumbers # this shows the contents of 'numbers'\n\n[1] 1 2 3 4 5\n\n# try typing the name wrong and see what error message you get\n\n\nnumbers &lt;- c(1, 2, 3, 4, 5)\n\nNumbers\n\nError: object 'Numbers' not found\n\nnubmers\n\nError: object 'nubmers' not found\n\n\nEven worse, you might have a typo in the original assignment, and then be very confused when the object you expect to exist doesn’t.\n\nnummbers &lt;- c(1, 2, 3, 4, 5)\n\nnumbers # oh dear, can you see the mistake here?\n\nError: object 'numbers' not found\n\n\n\n\n\nNesting functions is a common necessity. Make sure all the closing parentheses match up.\n\nsqrt(mean(seq(1, 10, 2)))\n\n[1] 2.236068\n\n# try adding/deleting/moving some closing parentheses\n\n\nsqrt(mean(seq(1, 10, 2)))) # too many!\n\nError in parse(text = input): &lt;text&gt;:1:26: unexpected ')'\n1: sqrt(mean(seq(1, 10, 2))))\n                             ^\n\n\n\nsqrt(mean(seq(1, 10, 2)) # not enough!\n\nError in parse(text = input): &lt;text&gt;:3:0: unexpected end of input\n1: sqrt(mean(seq(1, 10, 2)) # not enough!\n2: \n  ^\n\n\n\nsqrt(mean(seq(1, 10), 2)) # in the wrong place!\n\n[1] 2.345208\n\n\n\n\n\n\nNote that R will allow you to reuse a name that you already assigned something to. It will simply replace the thing that the name refers to. It will not ask if you’re sure you want to do that; it won’t mention it at all.\n\nnumber &lt;- 1\n\nnumber * 2\n\n[1] 2\n\nnumber &lt;- 2 # no warning when you reuse a name\n\nnumber * 2\n\n[1] 4\n\n\nIt is entirely possible for you to run lines of code out of order and get potentially confusing results as a consequence.\nYou might also run a line of code more than once, modifying an object in a way that you might not intend. This can be especially pernicious when you modify an object in a self-referential way.\n\nnumber &lt;- 1\n\nnumber &lt;- number * 2 # what if you run this a few times?\n\nnumber\n\n[1] 2\n\n\n\n\n\nnumbers &lt;- c(1, 2, 3, 4, 5)\n\n\n\n\n\n\nJust as easily as you can bring an object into existence, so too can you remove it. Clicking the charming little sweeping brush near the top of the Environment pane will remove everything that currently exists from your Environment. It’ll even ask if you’re sure–a rare instance of compassion on RStudio’s part.\nShould the need arise, you can also remove objects from your environment using the rm() function.\n\n# removing objects from the Environment\n\nrm(numbers) # remove a particular object by name\n\nrm(list = ls()) # remove everything in the global environment\n\nGenerally speaking, it’s a good habit to keep an eye on your Global Environment and not to be precious about its contents. Your code is the definitive record; if the instructions to make something are in there it can always be recreated.\n\n\n\n\n\n\n\nnumbers &lt;- c(1, 2, 3, 4, 5)\n\nnumbers * c(1, 2, 3, 4, 5) # makes sense...\n\n[1]  1  4  9 16 25\n\nnumbers * c(1, 2) # what happens here?\n\nWarning in numbers * c(1, 2): longer object length is not a multiple of shorter\nobject length\n\n\n[1] 1 4 3 8 5\n\n\n\n\n\nEvery element in a vector must be of the same type (numeric, character, logical). If that is not the case, R will silently coerce the data into a single type.\n\nnumbers &lt;- c(1, 2, 3, 4, 5)\nnumbers\n\n[1] 1 2 3 4 5\n\nnumbers &lt;- c(1, 2, \"three\", 4, 5)\nnumbers \n\n[1] \"1\"     \"2\"     \"three\" \"4\"     \"5\"    \n\nnumbers &lt;- c(1, 2, \"3\", 4, 5)\nnumbers\n\n[1] \"1\" \"2\" \"3\" \"4\" \"5\"\n\nmean(numbers)\n\nWarning in mean.default(numbers): argument is not numeric or logical: returning\nNA\n\n\n[1] NA\n\n\n\n\n\nThe enforcement of the single-type rule for vectors can be especially confounding when importing data. It is not uncommon for coding errors or sneaky special characters to cause data to be imported in unexpected ways.\n\ndf &lt;- data.frame(a = c(1, 2, 3),\n                 b = c(\"one\", \"two\", \"three\"),\n                 c = c(1, 2, \"3\"))\n\nstr(df)\n\n'data.frame':   3 obs. of  3 variables:\n $ a: num  1 2 3\n $ b: chr  \"one\" \"two\" \"three\"\n $ c: chr  \"1\" \"2\" \"3\"\n\nmean(df$c)\n\nWarning in mean.default(df$c): argument is not numeric or logical: returning NA\n\n\n[1] NA\n\n\n\n\n\nCoercion can have some confusing consequences, if you are taken unawares by mixed data types.\n\n1 &lt; \"2\"\n\n[1] TRUE\n\n22 &lt; \"11\"\n\n[1] FALSE\n\n3 &gt; \"two\"\n\n[1] FALSE\n\n# why?\n\n\n\n\nCoercion can have some happy consequences. For instance, logical values (TRUE and FALSE) can be coerced into the numbers 1 and 0. A function that requires numeric input, such as sum() or mean(), if given logical input, will coerce the vector to numeric.\n\n# doing math with logicals\n\nbool &lt;- c(TRUE, FALSE, FALSE, TRUE)\nbool \n\n[1]  TRUE FALSE FALSE  TRUE\n\nas.numeric(bool)\n\n[1] 1 0 0 1\n\nsum(bool) # count of TRUEs\n\n[1] 2\n\nmean(bool) # proportion of TRUEs\n\n[1] 0.5\n\n\n\n\n\n\nA factor is a special data type in R used to represent categorical data. Internally, it stores the data as integers, but each unique integer is associated with a text label (the level) for that category.\n\ndata &lt;- c(\"female\", \"male\", \"male\", \"female\")\n\ndata_factor &lt;- factor(data)\n\ndata_factor\n\n[1] female male   male   female\nLevels: female male\n\nas.numeric(data_factor)\n\n[1] 1 2 2 1\n\n\nPerhaps our raw data coded a variable like this as numeric to begin with, and we want to add the category labels ourselves.\n\ndata &lt;- c(1, 2, 2, 1) # gender coded numerically\n\nfactor(data, levels = c(1, 2), labels = c(\"female\", \"male\"))\n\n[1] female male   male   female\nLevels: female male\n\n\n\n\nFor ordinal data, where the order of categories matters, we can specify the levels in order and use the ordered = TRUE argument.\n\n# with no order specified; levels are listed alphabetically\n\ndata &lt;- c(\"medium\", \"low\", \"high\", \"medium\", \"high\", \"high\")\n\nunordered &lt;- factor(data) \n\n\n\n\n\n\n\n\n\n\n\nordered &lt;- factor(data, \n                  levels = c(\"low\", \"medium\", \"high\"), \n                  ordered = TRUE)\n\n\n\n\n\n\n\n\n\n\nNote that this does not affect the raw data, but it means that if we plot a graph using this ordered factor later on, the values will appear in their correct, meaningful order, rather than just the default alphabetical order.\n\n# can you make an ordered factor out of this ordinal data?\n\nsurvey_data &lt;- c(\"agree\", \"agree\", \"disagree\", \"neutral\", \"disagree\")",
    "crumbs": [
      "Day 1: Intro to R",
      "Common causes of confusion"
    ]
  },
  {
    "objectID": "1_4_other-things.html#typos",
    "href": "1_4_other-things.html#typos",
    "title": "Common causes of confusion",
    "section": "",
    "text": "Any small typo in a name will case R to throw an error.\n\nnumbers &lt;- c(1, 2, 3, 4, 5)\n\nnumbers # this shows the contents of 'numbers'\n\n[1] 1 2 3 4 5\n\n# try typing the name wrong and see what error message you get\n\n\nnumbers &lt;- c(1, 2, 3, 4, 5)\n\nNumbers\n\nError: object 'Numbers' not found\n\nnubmers\n\nError: object 'nubmers' not found\n\n\nEven worse, you might have a typo in the original assignment, and then be very confused when the object you expect to exist doesn’t.\n\nnummbers &lt;- c(1, 2, 3, 4, 5)\n\nnumbers # oh dear, can you see the mistake here?\n\nError: object 'numbers' not found\n\n\n\n\n\nNesting functions is a common necessity. Make sure all the closing parentheses match up.\n\nsqrt(mean(seq(1, 10, 2)))\n\n[1] 2.236068\n\n# try adding/deleting/moving some closing parentheses\n\n\nsqrt(mean(seq(1, 10, 2)))) # too many!\n\nError in parse(text = input): &lt;text&gt;:1:26: unexpected ')'\n1: sqrt(mean(seq(1, 10, 2))))\n                             ^\n\n\n\nsqrt(mean(seq(1, 10, 2)) # not enough!\n\nError in parse(text = input): &lt;text&gt;:3:0: unexpected end of input\n1: sqrt(mean(seq(1, 10, 2)) # not enough!\n2: \n  ^\n\n\n\nsqrt(mean(seq(1, 10), 2)) # in the wrong place!\n\n[1] 2.345208",
    "crumbs": [
      "Day 1: Intro to R",
      "Common causes of confusion"
    ]
  },
  {
    "objectID": "1_4_other-things.html#overwriting",
    "href": "1_4_other-things.html#overwriting",
    "title": "Common causes of confusion",
    "section": "",
    "text": "Note that R will allow you to reuse a name that you already assigned something to. It will simply replace the thing that the name refers to. It will not ask if you’re sure you want to do that; it won’t mention it at all.\n\nnumber &lt;- 1\n\nnumber * 2\n\n[1] 2\n\nnumber &lt;- 2 # no warning when you reuse a name\n\nnumber * 2\n\n[1] 4\n\n\nIt is entirely possible for you to run lines of code out of order and get potentially confusing results as a consequence.\nYou might also run a line of code more than once, modifying an object in a way that you might not intend. This can be especially pernicious when you modify an object in a self-referential way.\n\nnumber &lt;- 1\n\nnumber &lt;- number * 2 # what if you run this a few times?\n\nnumber\n\n[1] 2\n\n\n\n\n\nnumbers &lt;- c(1, 2, 3, 4, 5)\n\n\n\n\n\n\nJust as easily as you can bring an object into existence, so too can you remove it. Clicking the charming little sweeping brush near the top of the Environment pane will remove everything that currently exists from your Environment. It’ll even ask if you’re sure–a rare instance of compassion on RStudio’s part.\nShould the need arise, you can also remove objects from your environment using the rm() function.\n\n# removing objects from the Environment\n\nrm(numbers) # remove a particular object by name\n\nrm(list = ls()) # remove everything in the global environment\n\nGenerally speaking, it’s a good habit to keep an eye on your Global Environment and not to be precious about its contents. Your code is the definitive record; if the instructions to make something are in there it can always be recreated.",
    "crumbs": [
      "Day 1: Intro to R",
      "Common causes of confusion"
    ]
  },
  {
    "objectID": "1_4_other-things.html#vectors",
    "href": "1_4_other-things.html#vectors",
    "title": "Common causes of confusion",
    "section": "",
    "text": "numbers &lt;- c(1, 2, 3, 4, 5)\n\nnumbers * c(1, 2, 3, 4, 5) # makes sense...\n\n[1]  1  4  9 16 25\n\nnumbers * c(1, 2) # what happens here?\n\nWarning in numbers * c(1, 2): longer object length is not a multiple of shorter\nobject length\n\n\n[1] 1 4 3 8 5\n\n\n\n\n\nEvery element in a vector must be of the same type (numeric, character, logical). If that is not the case, R will silently coerce the data into a single type.\n\nnumbers &lt;- c(1, 2, 3, 4, 5)\nnumbers\n\n[1] 1 2 3 4 5\n\nnumbers &lt;- c(1, 2, \"three\", 4, 5)\nnumbers \n\n[1] \"1\"     \"2\"     \"three\" \"4\"     \"5\"    \n\nnumbers &lt;- c(1, 2, \"3\", 4, 5)\nnumbers\n\n[1] \"1\" \"2\" \"3\" \"4\" \"5\"\n\nmean(numbers)\n\nWarning in mean.default(numbers): argument is not numeric or logical: returning\nNA\n\n\n[1] NA\n\n\n\n\n\nThe enforcement of the single-type rule for vectors can be especially confounding when importing data. It is not uncommon for coding errors or sneaky special characters to cause data to be imported in unexpected ways.\n\ndf &lt;- data.frame(a = c(1, 2, 3),\n                 b = c(\"one\", \"two\", \"three\"),\n                 c = c(1, 2, \"3\"))\n\nstr(df)\n\n'data.frame':   3 obs. of  3 variables:\n $ a: num  1 2 3\n $ b: chr  \"one\" \"two\" \"three\"\n $ c: chr  \"1\" \"2\" \"3\"\n\nmean(df$c)\n\nWarning in mean.default(df$c): argument is not numeric or logical: returning NA\n\n\n[1] NA\n\n\n\n\n\nCoercion can have some confusing consequences, if you are taken unawares by mixed data types.\n\n1 &lt; \"2\"\n\n[1] TRUE\n\n22 &lt; \"11\"\n\n[1] FALSE\n\n3 &gt; \"two\"\n\n[1] FALSE\n\n# why?\n\n\n\n\nCoercion can have some happy consequences. For instance, logical values (TRUE and FALSE) can be coerced into the numbers 1 and 0. A function that requires numeric input, such as sum() or mean(), if given logical input, will coerce the vector to numeric.\n\n# doing math with logicals\n\nbool &lt;- c(TRUE, FALSE, FALSE, TRUE)\nbool \n\n[1]  TRUE FALSE FALSE  TRUE\n\nas.numeric(bool)\n\n[1] 1 0 0 1\n\nsum(bool) # count of TRUEs\n\n[1] 2\n\nmean(bool) # proportion of TRUEs\n\n[1] 0.5",
    "crumbs": [
      "Day 1: Intro to R",
      "Common causes of confusion"
    ]
  },
  {
    "objectID": "1_4_other-things.html#factors",
    "href": "1_4_other-things.html#factors",
    "title": "Common causes of confusion",
    "section": "",
    "text": "A factor is a special data type in R used to represent categorical data. Internally, it stores the data as integers, but each unique integer is associated with a text label (the level) for that category.\n\ndata &lt;- c(\"female\", \"male\", \"male\", \"female\")\n\ndata_factor &lt;- factor(data)\n\ndata_factor\n\n[1] female male   male   female\nLevels: female male\n\nas.numeric(data_factor)\n\n[1] 1 2 2 1\n\n\nPerhaps our raw data coded a variable like this as numeric to begin with, and we want to add the category labels ourselves.\n\ndata &lt;- c(1, 2, 2, 1) # gender coded numerically\n\nfactor(data, levels = c(1, 2), labels = c(\"female\", \"male\"))\n\n[1] female male   male   female\nLevels: female male\n\n\n\n\nFor ordinal data, where the order of categories matters, we can specify the levels in order and use the ordered = TRUE argument.\n\n# with no order specified; levels are listed alphabetically\n\ndata &lt;- c(\"medium\", \"low\", \"high\", \"medium\", \"high\", \"high\")\n\nunordered &lt;- factor(data) \n\n\n\n\n\n\n\n\n\n\n\nordered &lt;- factor(data, \n                  levels = c(\"low\", \"medium\", \"high\"), \n                  ordered = TRUE)\n\n\n\n\n\n\n\n\n\n\nNote that this does not affect the raw data, but it means that if we plot a graph using this ordered factor later on, the values will appear in their correct, meaningful order, rather than just the default alphabetical order.\n\n# can you make an ordered factor out of this ordinal data?\n\nsurvey_data &lt;- c(\"agree\", \"agree\", \"disagree\", \"neutral\", \"disagree\")",
    "crumbs": [
      "Day 1: Intro to R",
      "Common causes of confusion"
    ]
  },
  {
    "objectID": "1_4_other-things_presentation.html#typos",
    "href": "1_4_other-things_presentation.html#typos",
    "title": "R Faculty Workshop",
    "section": "Typos",
    "text": "Typos"
  },
  {
    "objectID": "1_4_other-things_presentation.html#overwriting",
    "href": "1_4_other-things_presentation.html#overwriting",
    "title": "R Faculty Workshop",
    "section": "Overwriting",
    "text": "Overwriting\n\nnumber &lt;- 1\n\nnumber * 2\n\n[1] 2\n\nnumber &lt;- 2 # no warning when you reuse a name\n\nnumber * 2\n\n[1] 4\n\n\n\nnumber &lt;- 1\n\nnumber &lt;- number * 2 # what if you run this a few times?\n\nnumber\n\n[1] 2"
  },
  {
    "objectID": "1_4_other-things_presentation.html#vectors",
    "href": "1_4_other-things_presentation.html#vectors",
    "title": "R Faculty Workshop",
    "section": "Vectors",
    "text": "Vectors"
  },
  {
    "objectID": "1_4_other-things_presentation.html#factors",
    "href": "1_4_other-things_presentation.html#factors",
    "title": "R Faculty Workshop",
    "section": "Factors",
    "text": "Factors\nA factor is a special data type in R used to represent categorical data. Internally, it stores the data as integers, but each unique integer is associated with a text label (the level) for that category.\n\ndata &lt;- c(\"female\", \"male\", \"male\", \"female\")\n\ndata_factor &lt;- factor(data)\n\ndata_factor\n\n[1] female male   male   female\nLevels: female male\n\nas.numeric(data_factor)\n\n[1] 1 2 2 1"
  },
  {
    "objectID": "1_1_intro-to-r.html",
    "href": "1_1_intro-to-r.html",
    "title": "Introduction to R and RStudio",
    "section": "",
    "text": "R is a coding language specialized for statistical computing and data analysis. It is free and open-source (though there is a cloud-based version which can be paid for and can have advantages especially in the classroom).\nSome of R’s capabilities:\n\nImport and create data files in various formats\nClean and organize data\nAnalyze and visualize the data\nCommunicate the results in various formats (pdf research paper, website, presentation slides)\nGenerate random data, execute functions repeatedly, useful for simulations, bootstrapping etc\nOther programmatic tasks, e.g. web-scraping, using APIs\n\n\n\n\n\n\nIt might seem daunting to learn R if you have no experience with coding, but the basic idea is that you have some data, like you are familiar with from a regular Excel or Google Sheets spreadsheet, and you perform operations on your data using functions a lot like you would in Excel/Sheets. For example, you might compute an average in Sheets by typing =AVERAGE(A1:A10). In R you might type mean(my_data$column_a). The specifics of the function names are different, but the basic idea is the same.\nA major difference between working with data in Excel vs. R is the separation of data from code. Rather than writing functions to manipulate or analyze data directly in your spreadsheet, code is written in a separate code file, which references but does not modify the source data file (unless you tell it to).\n\n\n\nExcel Spreadsheet\n\n\n\n\nA\n\n\n1\n\n\n2\n\n\n3\n\n\n4\n\n\n5\n\n\n=AVERAGE(A2:A6)\n\n\n\n\n\n\n\n\n\n\nR Data\n\n\n\n\n\n\nA\n\n\n\n\n1\n\n\n2\n\n\n3\n\n\n4\n\n\n5\n\n\n\n\n\n\n\n\nR Code\n\nmean(data$A)\n\n[1] 3\n\nsum(data$A)\n\n[1] 15\n\nsd(data$A)\n\n[1] 1.581139\n\n\n\n\n\n\n\n\n\n\n\n\n\nRStudio is the interface we’ll use to write and run R code and see its output. The basic interface has 4 panels, each with a few tabs:\n\nTop-left: Code editor / data viewer\n\nOpen, edit, and save code documents\nExecute code within files\nView data\nYou can have multiple ‘tabs’ open at once,\n\nBottom-left: R console\n\nYou can type code directly and run it by pressing enter.\nYou won’t be saving your code as a document like when you type in in the editor, so this is useful for testing something simple out\n\nTop-right: Environment\n\nAs you execute code you may be creating objects like sets of numbers of data.frames. Those objects will appear here.\nYou can click the name of some objects, like data.frames, and it will open a view of the data as a tab in the editor pane\n\nBottom-right: Files/folders, Plots, Viewer, help window\n\nYou can navigate the file tree\nAnd get Help with functions\nAs well as seeing plots and other kinds of output\n\n\n\n\n\n\nThe R language has many functions built in. Generally speaking, you can find a way to do pretty much anything you would like to do using just ‘base’ R.\nHowever there are many common tasks that are a bit tedious or unintuitive to do using base R. One of R’s strengths is how extensible it is: anyone can write their own functions, turn the code into an R package, and make that package available to other R users.\n\n\n\n\n\n\n\nThe tidyverse package is a container for multiple individual packages. The whole family of tidyverse packages are written with a consistent syntax and logic, and are widely used for data analysis. readr handles importing data, dplyr and tidyr have many functions for data cleaning and manipulation, stringr, lubridate, and forcats are specialized for working with text, dates, and categorical variables respectively; ggplot2 makes graphs; and tidymodels is for modelling.\n\n\n\nThe extended ecosystem includes packages specialized for almost any kind of analysis you can think of. To give a few examples…\n\nStructural equation modeling (lavaan)\nMeta-analysis (metafor)\nLinear mixed effects models (lme4, simr)\nBootstrapping (boot)\nBayesian models (brms, rstanarm)\nNetwork analyses (igraph, ggraph, tidygraph, qgraph, bootnet)\nLanguage analysis (tidytext, quanteda)\nAudio analysis (tuneR, seewave)\nMachine learning (tidymodels)\n\n\n\n\nE.g. maps (sf, leaflet)\n\nlibrary(leaflet)\n  \nleaflet() |&gt;\n  addProviderTiles(\"NASAGIBS.ViirsEarthAtNight2012\") |&gt;\n  addMarkers(lng = -73.96339268916061,\n             lat = 40.80949994182454, \n             popup = \"Hello from Barnard!\")\n\n\n\n\n\n\n\n\n\n\nE.g. plotly\n\n\n\n\n\n\n\n\n\n\ninstall.packages(\"tidyverse\")\n\ninstall.packages(\"lme4\")\n\nPackages only need to be installed on your system once.\n\n\n\nIf you are just using one function from a package as a one-off, you can use the double-colon :: operator in the form package::function(), i.e.\n\n# package::function syntax\n\ndplyr::filter(...)\n\ntidyr::pivot_longer(...)\n\nlme4::lmer(...)\n\nIf you will be using a package’s functions repeatedly, it can be preferable to activate the entire package using the library() function.\n\n# activate installed packages first with library()\n\nlibrary(tidyverse)\nlibrary(lme4)\n\n# then use functions\n\nlmer(...)\n\nNote that a package only needs to be installed once on your system (or in a new posit.cloud project), but if you are using the library() method to activate the package, it must be done every time you have a new ‘session’ in R.",
    "crumbs": [
      "Day 1: Intro to R",
      "Introduction to R and RStudio"
    ]
  },
  {
    "objectID": "1_1_intro-to-r.html#why-r",
    "href": "1_1_intro-to-r.html#why-r",
    "title": "Introduction to R and RStudio",
    "section": "",
    "text": "R is a coding language specialized for statistical computing and data analysis. It is free and open-source (though there is a cloud-based version which can be paid for and can have advantages especially in the classroom).\nSome of R’s capabilities:\n\nImport and create data files in various formats\nClean and organize data\nAnalyze and visualize the data\nCommunicate the results in various formats (pdf research paper, website, presentation slides)\nGenerate random data, execute functions repeatedly, useful for simulations, bootstrapping etc\nOther programmatic tasks, e.g. web-scraping, using APIs",
    "crumbs": [
      "Day 1: Intro to R",
      "Introduction to R and RStudio"
    ]
  },
  {
    "objectID": "1_1_intro-to-r.html#the-general-workflow",
    "href": "1_1_intro-to-r.html#the-general-workflow",
    "title": "Introduction to R and RStudio",
    "section": "",
    "text": "It might seem daunting to learn R if you have no experience with coding, but the basic idea is that you have some data, like you are familiar with from a regular Excel or Google Sheets spreadsheet, and you perform operations on your data using functions a lot like you would in Excel/Sheets. For example, you might compute an average in Sheets by typing =AVERAGE(A1:A10). In R you might type mean(my_data$column_a). The specifics of the function names are different, but the basic idea is the same.\nA major difference between working with data in Excel vs. R is the separation of data from code. Rather than writing functions to manipulate or analyze data directly in your spreadsheet, code is written in a separate code file, which references but does not modify the source data file (unless you tell it to).\n\n\n\nExcel Spreadsheet\n\n\n\n\nA\n\n\n1\n\n\n2\n\n\n3\n\n\n4\n\n\n5\n\n\n=AVERAGE(A2:A6)\n\n\n\n\n\n\n\n\n\n\nR Data\n\n\n\n\n\n\nA\n\n\n\n\n1\n\n\n2\n\n\n3\n\n\n4\n\n\n5\n\n\n\n\n\n\n\n\nR Code\n\nmean(data$A)\n\n[1] 3\n\nsum(data$A)\n\n[1] 15\n\nsd(data$A)\n\n[1] 1.581139\n\n\n\n\n\n\n\n\n\n\n\n\n\nRStudio is the interface we’ll use to write and run R code and see its output. The basic interface has 4 panels, each with a few tabs:\n\nTop-left: Code editor / data viewer\n\nOpen, edit, and save code documents\nExecute code within files\nView data\nYou can have multiple ‘tabs’ open at once,\n\nBottom-left: R console\n\nYou can type code directly and run it by pressing enter.\nYou won’t be saving your code as a document like when you type in in the editor, so this is useful for testing something simple out\n\nTop-right: Environment\n\nAs you execute code you may be creating objects like sets of numbers of data.frames. Those objects will appear here.\nYou can click the name of some objects, like data.frames, and it will open a view of the data as a tab in the editor pane\n\nBottom-right: Files/folders, Plots, Viewer, help window\n\nYou can navigate the file tree\nAnd get Help with functions\nAs well as seeing plots and other kinds of output",
    "crumbs": [
      "Day 1: Intro to R",
      "Introduction to R and RStudio"
    ]
  },
  {
    "objectID": "1_1_intro-to-r.html#additional-packages",
    "href": "1_1_intro-to-r.html#additional-packages",
    "title": "Introduction to R and RStudio",
    "section": "",
    "text": "The R language has many functions built in. Generally speaking, you can find a way to do pretty much anything you would like to do using just ‘base’ R.\nHowever there are many common tasks that are a bit tedious or unintuitive to do using base R. One of R’s strengths is how extensible it is: anyone can write their own functions, turn the code into an R package, and make that package available to other R users.\n\n\n\n\n\n\n\nThe tidyverse package is a container for multiple individual packages. The whole family of tidyverse packages are written with a consistent syntax and logic, and are widely used for data analysis. readr handles importing data, dplyr and tidyr have many functions for data cleaning and manipulation, stringr, lubridate, and forcats are specialized for working with text, dates, and categorical variables respectively; ggplot2 makes graphs; and tidymodels is for modelling.\n\n\n\nThe extended ecosystem includes packages specialized for almost any kind of analysis you can think of. To give a few examples…\n\nStructural equation modeling (lavaan)\nMeta-analysis (metafor)\nLinear mixed effects models (lme4, simr)\nBootstrapping (boot)\nBayesian models (brms, rstanarm)\nNetwork analyses (igraph, ggraph, tidygraph, qgraph, bootnet)\nLanguage analysis (tidytext, quanteda)\nAudio analysis (tuneR, seewave)\nMachine learning (tidymodels)\n\n\n\n\nE.g. maps (sf, leaflet)\n\nlibrary(leaflet)\n  \nleaflet() |&gt;\n  addProviderTiles(\"NASAGIBS.ViirsEarthAtNight2012\") |&gt;\n  addMarkers(lng = -73.96339268916061,\n             lat = 40.80949994182454, \n             popup = \"Hello from Barnard!\")\n\n\n\n\n\n\n\n\n\n\nE.g. plotly\n\n\n\n\n\n\n\n\n\n\ninstall.packages(\"tidyverse\")\n\ninstall.packages(\"lme4\")\n\nPackages only need to be installed on your system once.\n\n\n\nIf you are just using one function from a package as a one-off, you can use the double-colon :: operator in the form package::function(), i.e.\n\n# package::function syntax\n\ndplyr::filter(...)\n\ntidyr::pivot_longer(...)\n\nlme4::lmer(...)\n\nIf you will be using a package’s functions repeatedly, it can be preferable to activate the entire package using the library() function.\n\n# activate installed packages first with library()\n\nlibrary(tidyverse)\nlibrary(lme4)\n\n# then use functions\n\nlmer(...)\n\nNote that a package only needs to be installed once on your system (or in a new posit.cloud project), but if you are using the library() method to activate the package, it must be done every time you have a new ‘session’ in R.",
    "crumbs": [
      "Day 1: Intro to R",
      "Introduction to R and RStudio"
    ]
  },
  {
    "objectID": "1_1_intro-to-r_presentation.html#why-r",
    "href": "1_1_intro-to-r_presentation.html#why-r",
    "title": "R Faculty Workshop",
    "section": "Why R?",
    "text": "Why R?\nSome of R’s capabilities:\n\nImport and create data files in various formats\nClean and organize data\nAnalyze and visualize the data\nCommunicate the results in various formats (pdf research paper, website, presentation slides)\nGenerate random data, execute functions repeatedly, useful for simulations, bootstrapping etc\nOther programmatic tasks, e.g. web-scraping, using APIs"
  },
  {
    "objectID": "1_1_intro-to-r_presentation.html#the-general-workflow",
    "href": "1_1_intro-to-r_presentation.html#the-general-workflow",
    "title": "R Faculty Workshop",
    "section": "The general workflow",
    "text": "The general workflow"
  },
  {
    "objectID": "1_1_intro-to-r_presentation.html#additional-packages",
    "href": "1_1_intro-to-r_presentation.html#additional-packages",
    "title": "R Faculty Workshop",
    "section": "Additional packages",
    "text": "Additional packages\n“Base-R” and its extended ecosystem"
  },
  {
    "objectID": "1_2_basics_presentation.html#writing-and-running-code",
    "href": "1_2_basics_presentation.html#writing-and-running-code",
    "title": "R Faculty Workshop",
    "section": "Writing and running code",
    "text": "Writing and running code\n\nOne line at a time:\n\nRun button at top-right of editor pane \nCommand (or Ctrl) ⌘ Return ⏎ (advances cursor to next line)\nOption (or Alt) ⌥ + Return ⏎ (does not advance cursor)\n\nWhole script\n\nSource (runs code, doesn’t show output)\nSource with Echo (shows output)"
  },
  {
    "objectID": "1_2_basics_presentation.html#data-structures-and-syntax",
    "href": "1_2_basics_presentation.html#data-structures-and-syntax",
    "title": "R Faculty Workshop",
    "section": "Data structures and syntax",
    "text": "Data structures and syntax"
  },
  {
    "objectID": "1_2_basics_presentation.html#assignment",
    "href": "1_2_basics_presentation.html#assignment",
    "title": "R Faculty Workshop",
    "section": "Assignment",
    "text": "Assignment\nR has a fancy assignment operator: &lt;-.1\n\n\nnumbers &lt;- c(1, 2, 3, 4, 5)\n\nMost other coding languages tend to use a boring = for assignment. Sure it’s nice not having to type an extra character, but there’s a keyboard shortcut to quickly add an &lt;- in RStudio: Option/Alt + -. And philosophically, the &lt;- arrow conveys the inherent directionality of the assignment operation. The object is assigned to the name; the object and its name are not equal and so the = arguably gives a misleading impression of the two things being one and the same. (Also, to let you in on a secret, = also works for assignment in R.)"
  },
  {
    "objectID": "1_2_basics_presentation.html#functions",
    "href": "1_2_basics_presentation.html#functions",
    "title": "R Faculty Workshop",
    "section": "Functions",
    "text": "Functions\nMany of the things we eventually want to do involve functions. To use a function, type its name, followed by parentheses. Any inputs or other arguments you need to specify go inside the parentheses.\n\nsum(c(1, 2, 3, 4, 5)) # sum() takes a numeric vector as input\n\n[1] 15\n\n# use sum() to get the total of a vector of numbers of your own\n# run the code and make sure you get the answer you're expecting"
  },
  {
    "objectID": "1_2_basics_presentation.html#working-with-vectors",
    "href": "1_2_basics_presentation.html#working-with-vectors",
    "title": "R Faculty Workshop",
    "section": "Working with vectors",
    "text": "Working with vectors"
  },
  {
    "objectID": "1_2_basics_presentation.html#missing-values",
    "href": "1_2_basics_presentation.html#missing-values",
    "title": "R Faculty Workshop",
    "section": "Missing Values",
    "text": "Missing Values\nTo anticipate a problem we often run into when working with real data, sometimes our data includes missing values. R has a special placeholder for missing values: NA.\n\nnumbers &lt;- c(1, 2, NA, 4, 5)\n\nmean(numbers)\n\n[1] NA\n\n# can you solve the problem by looking at the help page for the mean function?"
  },
  {
    "objectID": "1_2_basics_presentation.html#data.frames",
    "href": "1_2_basics_presentation.html#data.frames",
    "title": "R Faculty Workshop",
    "section": "Data.frames",
    "text": "Data.frames\n\ndf &lt;- data.frame(a = c(1, 2, 3, 4, 5),\n                 b = c(6, 7, 8, 9, 10),\n                 c = c(\"this\", \"is\", \"a\", \"text\", \"column\"),\n                 d = c(TRUE, FALSE, FALSE, FALSE, TRUE))\n\nstr(df)\n\n'data.frame':   5 obs. of  4 variables:\n $ a: num  1 2 3 4 5\n $ b: num  6 7 8 9 10\n $ c: chr  \"this\" \"is\" \"a\" \"text\" ...\n $ d: logi  TRUE FALSE FALSE FALSE TRUE"
  },
  {
    "objectID": "1_2_basics_presentation.html#the-pipe",
    "href": "1_2_basics_presentation.html#the-pipe",
    "title": "R Faculty Workshop",
    "section": "The Pipe: |>",
    "text": "The Pipe: |&gt;\n\ndf |&gt; \n  summary()\n\n# is equivalent to \n\nsummary(df)\n\n\n# building a more elaborate pipeline \n# using the pipe operator and tidyverse functions\n\nlibrary(tidyverse)\n\ndf |&gt; \n  select(a, b) |&gt; \n  filter(a &gt; 3) |&gt; \n  mutate(c = a + b)\n\n\n\n\n\na\nb\nc\n\n\n\n\n4\n9\n13\n\n\n5\n10\n15"
  },
  {
    "objectID": "1_2_basics.html",
    "href": "1_2_basics.html",
    "title": "Basics of writing R code",
    "section": "",
    "text": "Resources\n\n\n\nDownload this file to accompany this section:\n\n my_first_r_file.R\n\nAfter you save it, double click it and it should open in the Editor pane in RStudio.\n\n\n\n\nWriting some code in an .R document (or opening an .R file with code already in it) does not cause the code to be executed automatically. You need to run the code yourself. You can run a single line of code at a time, or a whole section, or an entire script.\n\nOne line at a time:\n\nRun button at top-right of editor pane \nCommand (or Ctrl) ⌘ Return ⏎ (advances cursor to next line)\nOption (or Alt) ⌥ + Return ⏎ (does not advance cursor)\n\nWhole script\n\nSource (runs code, doesn’t show output)\nSource with Echo (shows output)\n\n\n\n\nTo start getting used to writing and running code, let’s use R as a calculator to do some sums.\n\n1 + 1\n\n[1] 2\n\n(-3)^2\n\n[1] 9\n\n# a line that starts with the # is a comment\n# comments do not get executed even if they contain valid code\n\n# 2 + 2\n\n# write a sum of your own. \n# run the code and make sure you get the answer you're expecting\n\n\n\n\n\n\n\nIn R, a vector is a collection of values of a single type of data. You can make one by using the c() function to collect things together.\n\n# numeric\nc(1, 2, 3, 4, 5)\n\n[1] 1 2 3 4 5\n\n# a colon can be used to produce a vector of consecutive integers\n1:5 \n\n[1] 1 2 3 4 5\n\n5:1\n\n[1] 5 4 3 2 1\n\n1 # is just a numeric vector of length 1\n\n[1] 1\n\n\n\n\n\n\n# character\nc(\"hello\", \"world\")\n\n[1] \"hello\" \"world\"\n\n# logical\nc(TRUE, FALSE)\n\n[1]  TRUE FALSE\n\n\n\n\n\n\nR has a fancy assignment operator: &lt;-.1\n\nYou assign things to a name by typing something like:\n\nnumbers &lt;- c(1, 2, 3, 4, 5)\n\nAlmost anything can be assigned to a name. In the example here the vector c(1, 2, 3, 4, 5) was assigned to the name numbers. But in other situations you might assign an entire dataset, a statistical model object, a function, or something else. Whatever it is you’re assigning, giving it a name allows to you perform subsequent operations more easily, and choosing appropriate names makes your code easier to understand.\n\n\nThe name can be almost anything you like; it just can’t start with a number or contain spaces or special characters other than _ (underscore) and . (period). No spaces! It can have uppercase characters as well as lowercase, but note that when it comes time to use the name later you will need to type it exactly right, including capitalization. So you can make life a little easier for yourself by using a consistent naming convention, ideally avoiding capital letters altogether.\n\n# valid name examples ✅\n\ndata &lt;- \"works\"\n\ngood_name &lt;- \"fine\"\n\n.ValidName &lt;- \"works, watch out for the capitals\"\n\nlong_name_for_a_variable &lt;- \"sure, bit long to type though\"\n\n\n# invalid names ❌ \n\n1badname &lt;- \"won't work\"\n\nworse name &lt;- \"can't have spaces\"\n\n# backticks allow for otherwise unacceptable names\n`1bad name` &lt;- \"will work\"\n\n\n\n\n\n\n\n\n\nWhen you run the code numbers &lt;- c(1, 2, 3, 4, 5) or any other assignment operation, you generally won’t see any output in the console. What you will see, however, is something new appear in your Global Environment, the pane in the top-right of the RStudio window.\n\n\n\n\nMany of the things we eventually want to do involve functions. To use a function, type its name, followed by parentheses. Any inputs or other arguments you need to specify go inside the parentheses.\n\nsum(c(1, 2, 3, 4, 5)) # sum() takes a numeric vector as input\n\n[1] 15\n\n# use sum() to get the total of a vector of numbers of your own\n# run the code and make sure you get the answer you're expecting\n\n\n\nMost usefully, we can use a named object we have created as input to a function. So rather than having to type or copy/paste the original vector c(1, 2, 3, 4, 5), we can give it a name and feed that name into a function that expects a numeric vector as input.\n\nnumbers &lt;- c(1, 2, 3, 4, 5)\n\nsum(numbers)\n\n[1] 15\n\nlength(numbers)\n\n[1] 5\n\nmean(numbers)\n\n[1] 3\n\nsd(numbers)\n\n[1] 1.581139\n\nmin(numbers)\n\n[1] 1\n\nmax(numbers)\n\n[1] 5\n\n\n\n\n\nA function generally has one or more “arguments”, to which you supply parameters. For example, the mean() function’s first argument is the set of numbers you want to compute the mean of.\nWhen you need to specify more than one argument, they are separated by a comma. Arguments usually have names. You don’t necessarily have to type the name of the argument, because of R’s positional matching.\nThe seq() function, for example, produces a sequence of numbers according to three arguments, from, to, and by.\n\nseq(from = 1, to = 10, by = 2)\n\n[1] 1 3 5 7 9\n\n\nIf you don’t type the names of the arguments, and just supply three values, R matches them by position, so this gives exactly the same output as the previous line of code because from, to, and by are the first three arguments respectively.\n\nseq(1, 10, 2) # gives same result as above\n\n[1] 1 3 5 7 9\n\n\nSuppose we actually wanted a sequence of 6 values. We could use the length.out argument. Now we definitely have to type the name at least of the by and length.out arguments, because positional matching won’t work.\n\nseq(from = 1, by = 2, length.out = 6) # argument names required\n\n[1]  1  3  5  7  9 11\n\n\nSo when do you type the argument names explicitly? Definitely when you need to, and maybe when you don’t: remember someone (including your future self, might eventually want to read and understand your code. Seeing the argument names can help with that.\n\n\n\nYou can get help with a function (to see what arguments it accepts, for example) by typing a question mark followed by the function name (without parentheses) in your console.\n\n?mean\n\nRunning the code will bring up the function’s help documentation in RStudio’s Help pane.\n\n\n\n\n\n\nYou can access individual element of a vector by supplying an index within square brackets. Note that indexing in R starts at 1 (the first element’s index is 1). This differs from many other coding languages which are 0-indexed (the first element’s index is 0).\n\nnumbers &lt;- c(3, 1, 4, 1, 5, 9)\n\nnumbers[1] # first element, because R uses 1-indexing\n\n[1] 3\n\nnumbers[1:3] # multiple consecutive elements\n\n[1] 3 1 4\n\n# can you pick out the 1st, 3rd, and 5th elements?\n\n\n\n\n\nnumbers &lt;- c(1, 2, 3, 4, 5)\n\nnumbers == 3\n\n[1] FALSE FALSE  TRUE FALSE FALSE\n\nnumbers != 3\n\n[1]  TRUE  TRUE FALSE  TRUE  TRUE\n\nnumbers %in% c(1, 3)\n\n[1]  TRUE FALSE  TRUE FALSE FALSE\n\nnumbers &lt; 3\n\n[1]  TRUE  TRUE FALSE FALSE FALSE\n\n\n\n\n\nYou can also select elements from a vector using a logical vector of the same length:\n\nnumbers[c(TRUE, TRUE, FALSE, FALSE, FALSE)]\n\n[1] 1 2\n\n\nThat’s not useful by itself, but how might you create a logical vector like that? By testing the vector with some condition! So the condition can be used to pick out the relevant elements directly.\n\nnumbers[numbers &lt; 3]\n\n[1] 1 2\n\n\n\n\n\n\nnumbers &lt;- c(1, 2, 3, 4, 5)\n\nnumbers * 2\n\n[1]  2  4  6  8 10\n\n6 - numbers\n\n[1] 5 4 3 2 1\n\nnumbers * numbers\n\n[1]  1  4  9 16 25\n\n\n\n\n\n\nsd(numbers) / sqrt(length(numbers)) # standard error\n\n[1] 0.7071068\n\nnumbers - mean(numbers) # deviations\n\n[1] -2 -1  0  1  2\n\n(numbers - mean(numbers))^2 # squared deviations\n\n[1] 4 1 0 1 4\n\n# can you compute the sum of squared deviations?\n\n\n\n\n\nTo anticipate a problem we often run into when working with real data, sometimes our data includes missing values. R has a special placeholder for missing values: NA.\n\nnumbers &lt;- c(1, 2, NA, 4, 5)\n\nmean(numbers)\n\n[1] NA\n\n# can you solve the problem by looking at the help page for the mean function?\n\n\n\n\nSo far we’ve been working with individual vectors. Sooner of later we’re going to want to work with a collection of different sets of numbers: a spreadsheet. R’s name for this kind of data structure is a data.frame. A data.frame is a collection of vectors; each column is a vector. Different columns can have different types (numeric, character, logical, date, etc), but each column will contain a single type of data. All columns must have the same length.\nMost commonly we have a data file already (a .csv or maybe an Excel file or some other format) and we read it in to R. However, to get a sense of how these objects work, and how to work with them, we can make one from scratch.\n\ndf &lt;- data.frame(a = c(1, 2, 3, 4, 5),\n                 b = c(6, 7, 8, 9, 10),\n                 c = c(\"this\", \"is\", \"a\", \"text\", \"column\"),\n                 d = c(TRUE, FALSE, FALSE, FALSE, TRUE))\n\nstr(df)\n\n'data.frame':   5 obs. of  4 variables:\n $ a: num  1 2 3 4 5\n $ b: num  6 7 8 9 10\n $ c: chr  \"this\" \"is\" \"a\" \"text\" ...\n $ d: logi  TRUE FALSE FALSE FALSE TRUE\n\n\n\n\n# get a quick summary of each column\n\nsummary(df)\n\n       a           b           c                 d          \n Min.   :1   Min.   : 6   Length:5           Mode :logical  \n 1st Qu.:2   1st Qu.: 7   Class :character   FALSE:3        \n Median :3   Median : 8   Mode  :character   TRUE :2        \n Mean   :3   Mean   : 8                                     \n 3rd Qu.:4   3rd Qu.: 9                                     \n Max.   :5   Max.   :10                                     \n\n\n\n\nR has many ways of picking out particular columns, rows, and individual values from a data.frame. The most useful is the $ dollar sign for referring to a column by name. The data.frame we just created has a column named “a”, so we can access the single vector that makes up that column by typing:\n\ndf$a\n\n[1] 1 2 3 4 5\n\n\nThen we can use all the functions, mathematical operations and everything else we’ve learned about so far to start working with the columns of our data.frame.\n\n# remember, a data.frame column is a vector like any other\n\ndf$a * 2\n\n[1]  2  4  6  8 10\n\ndf$a * df$b\n\n[1]  6 14 24 36 50\n\nmean(df$a)\n\n[1] 3\n\nmean(df$c)\n\nWarning in mean.default(df$c): argument is not numeric or logical: returning NA\n\n\n[1] NA\n\n\n\n\n\n\nWhen we start working with real data.frames, it will be convenient to string together different operations in an analytic pipeline using R’s pipe operator: |&gt;.2 Whatever is on the left of the pipe gets “piped” into the function on the next line as its first argument. That is very handy when a function is expecting a data.frame as its first argument. The tidyverse family of packages are all written with this syntax in mind, so they are great for building efficient and eloquent analytic pipelines.\n\ndf |&gt; \n  summary()\n\n# is equivalent to \n\nsummary(df)\n\nThe real power of this becomes apparent when you need to conduct a more elaborate sequence of steps. We can pass a data.frame from function to function, modifying it along the way. The pipe allows the code to be neatly segmented and readable as a set of instructions from top to bottom.\n\n# building a more elaborate pipeline \n# using the pipe operator and tidyverse functions\n\nlibrary(tidyverse)\n\ndf |&gt; \n  select(a, b) |&gt; \n  filter(a &gt; 3) |&gt; \n  mutate(c = a + b)\n\n\n\n\n\na\nb\nc\n\n\n\n\n4\n9\n13\n\n\n5\n10\n15",
    "crumbs": [
      "Day 1: Intro to R",
      "Basics of writing R code"
    ]
  },
  {
    "objectID": "1_2_basics.html#writing-and-running-code",
    "href": "1_2_basics.html#writing-and-running-code",
    "title": "Basics of writing R code",
    "section": "",
    "text": "Writing some code in an .R document (or opening an .R file with code already in it) does not cause the code to be executed automatically. You need to run the code yourself. You can run a single line of code at a time, or a whole section, or an entire script.\n\nOne line at a time:\n\nRun button at top-right of editor pane \nCommand (or Ctrl) ⌘ Return ⏎ (advances cursor to next line)\nOption (or Alt) ⌥ + Return ⏎ (does not advance cursor)\n\nWhole script\n\nSource (runs code, doesn’t show output)\nSource with Echo (shows output)\n\n\n\n\nTo start getting used to writing and running code, let’s use R as a calculator to do some sums.\n\n1 + 1\n\n[1] 2\n\n(-3)^2\n\n[1] 9\n\n# a line that starts with the # is a comment\n# comments do not get executed even if they contain valid code\n\n# 2 + 2\n\n# write a sum of your own. \n# run the code and make sure you get the answer you're expecting",
    "crumbs": [
      "Day 1: Intro to R",
      "Basics of writing R code"
    ]
  },
  {
    "objectID": "1_2_basics.html#data-structures-and-syntax",
    "href": "1_2_basics.html#data-structures-and-syntax",
    "title": "Basics of writing R code",
    "section": "",
    "text": "In R, a vector is a collection of values of a single type of data. You can make one by using the c() function to collect things together.\n\n# numeric\nc(1, 2, 3, 4, 5)\n\n[1] 1 2 3 4 5\n\n# a colon can be used to produce a vector of consecutive integers\n1:5 \n\n[1] 1 2 3 4 5\n\n5:1\n\n[1] 5 4 3 2 1\n\n1 # is just a numeric vector of length 1\n\n[1] 1\n\n\n\n\n\n\n# character\nc(\"hello\", \"world\")\n\n[1] \"hello\" \"world\"\n\n# logical\nc(TRUE, FALSE)\n\n[1]  TRUE FALSE",
    "crumbs": [
      "Day 1: Intro to R",
      "Basics of writing R code"
    ]
  },
  {
    "objectID": "1_2_basics.html#assignment",
    "href": "1_2_basics.html#assignment",
    "title": "Basics of writing R code",
    "section": "",
    "text": "R has a fancy assignment operator: &lt;-.1\n\nYou assign things to a name by typing something like:\n\nnumbers &lt;- c(1, 2, 3, 4, 5)\n\nAlmost anything can be assigned to a name. In the example here the vector c(1, 2, 3, 4, 5) was assigned to the name numbers. But in other situations you might assign an entire dataset, a statistical model object, a function, or something else. Whatever it is you’re assigning, giving it a name allows to you perform subsequent operations more easily, and choosing appropriate names makes your code easier to understand.\n\n\nThe name can be almost anything you like; it just can’t start with a number or contain spaces or special characters other than _ (underscore) and . (period). No spaces! It can have uppercase characters as well as lowercase, but note that when it comes time to use the name later you will need to type it exactly right, including capitalization. So you can make life a little easier for yourself by using a consistent naming convention, ideally avoiding capital letters altogether.\n\n# valid name examples ✅\n\ndata &lt;- \"works\"\n\ngood_name &lt;- \"fine\"\n\n.ValidName &lt;- \"works, watch out for the capitals\"\n\nlong_name_for_a_variable &lt;- \"sure, bit long to type though\"\n\n\n# invalid names ❌ \n\n1badname &lt;- \"won't work\"\n\nworse name &lt;- \"can't have spaces\"\n\n# backticks allow for otherwise unacceptable names\n`1bad name` &lt;- \"will work\"\n\n\n\n\n\n\n\n\n\nWhen you run the code numbers &lt;- c(1, 2, 3, 4, 5) or any other assignment operation, you generally won’t see any output in the console. What you will see, however, is something new appear in your Global Environment, the pane in the top-right of the RStudio window.",
    "crumbs": [
      "Day 1: Intro to R",
      "Basics of writing R code"
    ]
  },
  {
    "objectID": "1_2_basics.html#functions",
    "href": "1_2_basics.html#functions",
    "title": "Basics of writing R code",
    "section": "",
    "text": "Many of the things we eventually want to do involve functions. To use a function, type its name, followed by parentheses. Any inputs or other arguments you need to specify go inside the parentheses.\n\nsum(c(1, 2, 3, 4, 5)) # sum() takes a numeric vector as input\n\n[1] 15\n\n# use sum() to get the total of a vector of numbers of your own\n# run the code and make sure you get the answer you're expecting\n\n\n\nMost usefully, we can use a named object we have created as input to a function. So rather than having to type or copy/paste the original vector c(1, 2, 3, 4, 5), we can give it a name and feed that name into a function that expects a numeric vector as input.\n\nnumbers &lt;- c(1, 2, 3, 4, 5)\n\nsum(numbers)\n\n[1] 15\n\nlength(numbers)\n\n[1] 5\n\nmean(numbers)\n\n[1] 3\n\nsd(numbers)\n\n[1] 1.581139\n\nmin(numbers)\n\n[1] 1\n\nmax(numbers)\n\n[1] 5\n\n\n\n\n\nA function generally has one or more “arguments”, to which you supply parameters. For example, the mean() function’s first argument is the set of numbers you want to compute the mean of.\nWhen you need to specify more than one argument, they are separated by a comma. Arguments usually have names. You don’t necessarily have to type the name of the argument, because of R’s positional matching.\nThe seq() function, for example, produces a sequence of numbers according to three arguments, from, to, and by.\n\nseq(from = 1, to = 10, by = 2)\n\n[1] 1 3 5 7 9\n\n\nIf you don’t type the names of the arguments, and just supply three values, R matches them by position, so this gives exactly the same output as the previous line of code because from, to, and by are the first three arguments respectively.\n\nseq(1, 10, 2) # gives same result as above\n\n[1] 1 3 5 7 9\n\n\nSuppose we actually wanted a sequence of 6 values. We could use the length.out argument. Now we definitely have to type the name at least of the by and length.out arguments, because positional matching won’t work.\n\nseq(from = 1, by = 2, length.out = 6) # argument names required\n\n[1]  1  3  5  7  9 11\n\n\nSo when do you type the argument names explicitly? Definitely when you need to, and maybe when you don’t: remember someone (including your future self, might eventually want to read and understand your code. Seeing the argument names can help with that.\n\n\n\nYou can get help with a function (to see what arguments it accepts, for example) by typing a question mark followed by the function name (without parentheses) in your console.\n\n?mean\n\nRunning the code will bring up the function’s help documentation in RStudio’s Help pane.",
    "crumbs": [
      "Day 1: Intro to R",
      "Basics of writing R code"
    ]
  },
  {
    "objectID": "1_2_basics.html#working-with-vectors",
    "href": "1_2_basics.html#working-with-vectors",
    "title": "Basics of writing R code",
    "section": "",
    "text": "You can access individual element of a vector by supplying an index within square brackets. Note that indexing in R starts at 1 (the first element’s index is 1). This differs from many other coding languages which are 0-indexed (the first element’s index is 0).\n\nnumbers &lt;- c(3, 1, 4, 1, 5, 9)\n\nnumbers[1] # first element, because R uses 1-indexing\n\n[1] 3\n\nnumbers[1:3] # multiple consecutive elements\n\n[1] 3 1 4\n\n# can you pick out the 1st, 3rd, and 5th elements?\n\n\n\n\n\nnumbers &lt;- c(1, 2, 3, 4, 5)\n\nnumbers == 3\n\n[1] FALSE FALSE  TRUE FALSE FALSE\n\nnumbers != 3\n\n[1]  TRUE  TRUE FALSE  TRUE  TRUE\n\nnumbers %in% c(1, 3)\n\n[1]  TRUE FALSE  TRUE FALSE FALSE\n\nnumbers &lt; 3\n\n[1]  TRUE  TRUE FALSE FALSE FALSE\n\n\n\n\n\nYou can also select elements from a vector using a logical vector of the same length:\n\nnumbers[c(TRUE, TRUE, FALSE, FALSE, FALSE)]\n\n[1] 1 2\n\n\nThat’s not useful by itself, but how might you create a logical vector like that? By testing the vector with some condition! So the condition can be used to pick out the relevant elements directly.\n\nnumbers[numbers &lt; 3]\n\n[1] 1 2\n\n\n\n\n\n\nnumbers &lt;- c(1, 2, 3, 4, 5)\n\nnumbers * 2\n\n[1]  2  4  6  8 10\n\n6 - numbers\n\n[1] 5 4 3 2 1\n\nnumbers * numbers\n\n[1]  1  4  9 16 25\n\n\n\n\n\n\nsd(numbers) / sqrt(length(numbers)) # standard error\n\n[1] 0.7071068\n\nnumbers - mean(numbers) # deviations\n\n[1] -2 -1  0  1  2\n\n(numbers - mean(numbers))^2 # squared deviations\n\n[1] 4 1 0 1 4\n\n# can you compute the sum of squared deviations?",
    "crumbs": [
      "Day 1: Intro to R",
      "Basics of writing R code"
    ]
  },
  {
    "objectID": "1_2_basics.html#missing-values",
    "href": "1_2_basics.html#missing-values",
    "title": "Basics of writing R code",
    "section": "",
    "text": "To anticipate a problem we often run into when working with real data, sometimes our data includes missing values. R has a special placeholder for missing values: NA.\n\nnumbers &lt;- c(1, 2, NA, 4, 5)\n\nmean(numbers)\n\n[1] NA\n\n# can you solve the problem by looking at the help page for the mean function?",
    "crumbs": [
      "Day 1: Intro to R",
      "Basics of writing R code"
    ]
  },
  {
    "objectID": "1_2_basics.html#data.frames",
    "href": "1_2_basics.html#data.frames",
    "title": "Basics of writing R code",
    "section": "",
    "text": "So far we’ve been working with individual vectors. Sooner of later we’re going to want to work with a collection of different sets of numbers: a spreadsheet. R’s name for this kind of data structure is a data.frame. A data.frame is a collection of vectors; each column is a vector. Different columns can have different types (numeric, character, logical, date, etc), but each column will contain a single type of data. All columns must have the same length.\nMost commonly we have a data file already (a .csv or maybe an Excel file or some other format) and we read it in to R. However, to get a sense of how these objects work, and how to work with them, we can make one from scratch.\n\ndf &lt;- data.frame(a = c(1, 2, 3, 4, 5),\n                 b = c(6, 7, 8, 9, 10),\n                 c = c(\"this\", \"is\", \"a\", \"text\", \"column\"),\n                 d = c(TRUE, FALSE, FALSE, FALSE, TRUE))\n\nstr(df)\n\n'data.frame':   5 obs. of  4 variables:\n $ a: num  1 2 3 4 5\n $ b: num  6 7 8 9 10\n $ c: chr  \"this\" \"is\" \"a\" \"text\" ...\n $ d: logi  TRUE FALSE FALSE FALSE TRUE\n\n\n\n\n# get a quick summary of each column\n\nsummary(df)\n\n       a           b           c                 d          \n Min.   :1   Min.   : 6   Length:5           Mode :logical  \n 1st Qu.:2   1st Qu.: 7   Class :character   FALSE:3        \n Median :3   Median : 8   Mode  :character   TRUE :2        \n Mean   :3   Mean   : 8                                     \n 3rd Qu.:4   3rd Qu.: 9                                     \n Max.   :5   Max.   :10                                     \n\n\n\n\nR has many ways of picking out particular columns, rows, and individual values from a data.frame. The most useful is the $ dollar sign for referring to a column by name. The data.frame we just created has a column named “a”, so we can access the single vector that makes up that column by typing:\n\ndf$a\n\n[1] 1 2 3 4 5\n\n\nThen we can use all the functions, mathematical operations and everything else we’ve learned about so far to start working with the columns of our data.frame.\n\n# remember, a data.frame column is a vector like any other\n\ndf$a * 2\n\n[1]  2  4  6  8 10\n\ndf$a * df$b\n\n[1]  6 14 24 36 50\n\nmean(df$a)\n\n[1] 3\n\nmean(df$c)\n\nWarning in mean.default(df$c): argument is not numeric or logical: returning NA\n\n\n[1] NA",
    "crumbs": [
      "Day 1: Intro to R",
      "Basics of writing R code"
    ]
  },
  {
    "objectID": "1_2_basics.html#the-pipe",
    "href": "1_2_basics.html#the-pipe",
    "title": "Basics of writing R code",
    "section": "",
    "text": "When we start working with real data.frames, it will be convenient to string together different operations in an analytic pipeline using R’s pipe operator: |&gt;.2 Whatever is on the left of the pipe gets “piped” into the function on the next line as its first argument. That is very handy when a function is expecting a data.frame as its first argument. The tidyverse family of packages are all written with this syntax in mind, so they are great for building efficient and eloquent analytic pipelines.\n\ndf |&gt; \n  summary()\n\n# is equivalent to \n\nsummary(df)\n\nThe real power of this becomes apparent when you need to conduct a more elaborate sequence of steps. We can pass a data.frame from function to function, modifying it along the way. The pipe allows the code to be neatly segmented and readable as a set of instructions from top to bottom.\n\n# building a more elaborate pipeline \n# using the pipe operator and tidyverse functions\n\nlibrary(tidyverse)\n\ndf |&gt; \n  select(a, b) |&gt; \n  filter(a &gt; 3) |&gt; \n  mutate(c = a + b)\n\n\n\n\n\na\nb\nc\n\n\n\n\n4\n9\n13\n\n\n5\n10\n15",
    "crumbs": [
      "Day 1: Intro to R",
      "Basics of writing R code"
    ]
  },
  {
    "objectID": "1_2_basics.html#footnotes",
    "href": "1_2_basics.html#footnotes",
    "title": "Basics of writing R code",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nMost other coding languages tend to use a boring = for assignment. Sure it’s nice not having to type an extra character, but there’s a keyboard shortcut to quickly add an &lt;- in RStudio: Option/Alt + -. And philosophically, the &lt;- arrow conveys the inherent directionality of the assignment operation. The object is assigned to the name; the object and its name are not equal and so the = arguably gives a misleading impression of the two things being one and the same. (Also, to let you in on a secret, = also works for assignment in R.)↩︎\nIf you’re looking at R code from elsewhere (e.g. looking up help online) you may see a different pipe: %&gt;%. The |&gt; pipe, called the “native” pipe, was only included as a feature of base R relatively recently. Until then, the %&gt;% pipe was provided by an external package (called magrittr. Get it?). In practice the pipes work similarly, so you can often just replace %&gt;% with |&gt; and it’ll work fine, but it’s worth being aware of.↩︎",
    "crumbs": [
      "Day 1: Intro to R",
      "Basics of writing R code"
    ]
  },
  {
    "objectID": "2_2_quarto_presentation.html#what-is-quarto",
    "href": "2_2_quarto_presentation.html#what-is-quarto",
    "title": "R Faculty Workshop",
    "section": "What is Quarto?",
    "text": "What is Quarto?\n“An open-source scientific and technical publishing system”\nWorks seamlessly within RStudio\nNext generation version of R Markdown.\nProvides an integrated workflow: Combines narrative text with code, output and visualizations in a single document, or cohesive collection of documents."
  },
  {
    "objectID": "2_2_quarto_presentation.html#working-with-quarto-documents",
    "href": "2_2_quarto_presentation.html#working-with-quarto-documents",
    "title": "R Faculty Workshop",
    "section": "Working with Quarto documents",
    "text": "Working with Quarto documents"
  },
  {
    "objectID": "2_2_quarto_presentation.html#getting-started",
    "href": "2_2_quarto_presentation.html#getting-started",
    "title": "R Faculty Workshop",
    "section": "Getting started",
    "text": "Getting started"
  },
  {
    "objectID": "2_2_quarto_presentation.html#advanced-features",
    "href": "2_2_quarto_presentation.html#advanced-features",
    "title": "R Faculty Workshop",
    "section": "Advanced Features",
    "text": "Advanced Features"
  },
  {
    "objectID": "2_2_quarto_presentation.html#additional-resources",
    "href": "2_2_quarto_presentation.html#additional-resources",
    "title": "R Faculty Workshop",
    "section": "Additional Resources",
    "text": "Additional Resources\n\nTutorial: Hello, Quarto\nQuarto OfficialDocumentation\nCarpentries: Reproducible Publications with Quarto\nQuarto Manuscripts\nQuarto Gallery (Examples)"
  },
  {
    "objectID": "2_3_quarto.html",
    "href": "2_3_quarto.html",
    "title": "Quarto",
    "section": "",
    "text": "“An open-source scientific and technical publishing system”\nWorks seamlessly within RStudio\nNext generation version of R Markdown.\nProvides an integrated workflow: Combines narrative text with code, output and visualizations in a single document, or cohesive collection of documents.\n\n\n\nSingle documents\n\nPDF article\nWord document\nHTML article\nHTML presentation\n\nCollection of documents\n\nBook (html and/or PDF)\nWebsite (html pages, navigation)\n\n\n\n\n\n\nReproducibility: Ensures that analyses and results can be consistently replicated, fostering transparency in research and teaching.\nEngaging Teaching Materials: Create interactive documents that combine theoretical explanations with practical code examples.\nEfficient Assignment Management: Design assignments where students can execute and modify code within the same document, streamlining grading and feedback.\nProfessional Reporting: Generate publication-ready reports and presentations directly from your analyses.\n\n\n\n\n\n\n\n\n\n\nFile &gt; New File &gt; Quarto Document\nYAML section\n---\ntitle: \"Untitled\"\n---\nText.\nCode chunks.\n\n# hello!\n\n\n\n\nSource vs Visual\n\n\n\n\n\n\nUse the “Render” button in RStudio to execute all code and generate the final output. Each render starts from a clean environment, ensuring that all results are reproducible; all code gets executed from scratch.\n\n\n\n\n\nThe _quarto.yml file.\nContains rendering instructions for the entire project, and things that will apply to each file.\n\n\n_quarto.yml\n\nproject:\n  type: website\n\nformat:\n  html:\n    toc: true\n\n\n\n\n\n\n\n\nManage bibliographies using .bib files.\nInsert citations using @citation_key.\nAutomatically generate reference sections.\n\n\n\nLabel figures and tables for easy cross-referencing within the text.\nAn image can be give an ID when inserted, e.g.\n![The R Logo](images/r-logo.png){#fig-logo}\n\n\n\n\n\n\nFigure 1: The R Logo\n\n\n\nTyping “As shown in @fig-logo, R has a perfectly pleasant logo.\" becomes:\nAs shown in Figure 1, R has a perfectly pleasant logo.\n\n\n\n\n\nTutorial: Hello, Quarto\nQuarto OfficialDocumentation\nCarpentries: Reproducible Publications with Quarto\nQuarto Manuscripts\nQuarto Gallery (Examples)",
    "crumbs": [
      "Day 2: Teaching with R",
      "Quarto"
    ]
  },
  {
    "objectID": "2_3_quarto.html#what-is-quarto",
    "href": "2_3_quarto.html#what-is-quarto",
    "title": "Quarto",
    "section": "",
    "text": "“An open-source scientific and technical publishing system”\nWorks seamlessly within RStudio\nNext generation version of R Markdown.\nProvides an integrated workflow: Combines narrative text with code, output and visualizations in a single document, or cohesive collection of documents.\n\n\n\nSingle documents\n\nPDF article\nWord document\nHTML article\nHTML presentation\n\nCollection of documents\n\nBook (html and/or PDF)\nWebsite (html pages, navigation)\n\n\n\n\n\n\nReproducibility: Ensures that analyses and results can be consistently replicated, fostering transparency in research and teaching.\nEngaging Teaching Materials: Create interactive documents that combine theoretical explanations with practical code examples.\nEfficient Assignment Management: Design assignments where students can execute and modify code within the same document, streamlining grading and feedback.\nProfessional Reporting: Generate publication-ready reports and presentations directly from your analyses.",
    "crumbs": [
      "Day 2: Teaching with R",
      "Quarto"
    ]
  },
  {
    "objectID": "2_3_quarto.html#getting-started",
    "href": "2_3_quarto.html#getting-started",
    "title": "Quarto",
    "section": "",
    "text": "File &gt; New File &gt; Quarto Document\nYAML section\n---\ntitle: \"Untitled\"\n---\nText.\nCode chunks.\n\n# hello!\n\n\n\n\nSource vs Visual\n\n\n\n\n\n\nUse the “Render” button in RStudio to execute all code and generate the final output. Each render starts from a clean environment, ensuring that all results are reproducible; all code gets executed from scratch.\n\n\n\n\n\nThe _quarto.yml file.\nContains rendering instructions for the entire project, and things that will apply to each file.\n\n\n_quarto.yml\n\nproject:\n  type: website\n\nformat:\n  html:\n    toc: true",
    "crumbs": [
      "Day 2: Teaching with R",
      "Quarto"
    ]
  },
  {
    "objectID": "2_3_quarto.html#advanced-features",
    "href": "2_3_quarto.html#advanced-features",
    "title": "Quarto",
    "section": "",
    "text": "Manage bibliographies using .bib files.\nInsert citations using @citation_key.\nAutomatically generate reference sections.\n\n\n\nLabel figures and tables for easy cross-referencing within the text.\nAn image can be give an ID when inserted, e.g.\n![The R Logo](images/r-logo.png){#fig-logo}\n\n\n\n\n\n\nFigure 1: The R Logo\n\n\n\nTyping “As shown in @fig-logo, R has a perfectly pleasant logo.\" becomes:\nAs shown in Figure 1, R has a perfectly pleasant logo.",
    "crumbs": [
      "Day 2: Teaching with R",
      "Quarto"
    ]
  },
  {
    "objectID": "2_3_quarto.html#additional-resources",
    "href": "2_3_quarto.html#additional-resources",
    "title": "Quarto",
    "section": "",
    "text": "Tutorial: Hello, Quarto\nQuarto OfficialDocumentation\nCarpentries: Reproducible Publications with Quarto\nQuarto Manuscripts\nQuarto Gallery (Examples)",
    "crumbs": [
      "Day 2: Teaching with R",
      "Quarto"
    ]
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Workshop overview",
    "section": "",
    "text": "Some notes about R and its ecosystem in general\n\n\n\nSyntax, data types, assignment, functions\n\n\n\nImporting data, cleaning, graphs, analyses\n\n\n\nOther things to look out for that can trip up new (and experienced) users\n\n\n\n\n\n\nPedagogy, grading, generative AI\n\n\n\nA web-based version of RStudio\n\n\n\nAn alternative document format with advantages for teaching\n\n\n\nExamples of how I use R and these additional tools in Statistics and Labs",
    "crumbs": [
      "Workshop overview"
    ]
  },
  {
    "objectID": "index.html#day-1-intro-to-r",
    "href": "index.html#day-1-intro-to-r",
    "title": "Workshop overview",
    "section": "",
    "text": "Some notes about R and its ecosystem in general\n\n\n\nSyntax, data types, assignment, functions\n\n\n\nImporting data, cleaning, graphs, analyses\n\n\n\nOther things to look out for that can trip up new (and experienced) users",
    "crumbs": [
      "Workshop overview"
    ]
  },
  {
    "objectID": "index.html#day-2-teaching-with-r",
    "href": "index.html#day-2-teaching-with-r",
    "title": "Workshop overview",
    "section": "",
    "text": "Pedagogy, grading, generative AI\n\n\n\nA web-based version of RStudio\n\n\n\nAn alternative document format with advantages for teaching\n\n\n\nExamples of how I use R and these additional tools in Statistics and Labs",
    "crumbs": [
      "Workshop overview"
    ]
  },
  {
    "objectID": "0_installing.html",
    "href": "0_installing.html",
    "title": "Installing R and RStudio",
    "section": "",
    "text": "You can install the necessary software on your own computer for free by following this link:\nhttps://posit.co/download/rstudio-desktop/\nAs the page will tell you, there are 2 separate components to install: R and RStudio. Follow the relevant links, making sure to pick the appropriate version for your operating system (Mac/Windows/Linux) where necessary.\n\nR (the R language itself)\n\nOn the download page for this you’ll see different links for different operating systems\n\nMacOS: There are different versions of R depending on whether you have a newer Mac with an Apple processor (M1, M2… etc), or an older one with an Intel processor. If you’re not sure which you have, search your computer for “system information”, which should open some information including which chip your computer has.\nWindows: Click the “Download R for Windows” link and look for “install R for the first time”\n\n\nRStudio (the software interface we use to write and run R code)\n\nJust click the big download button; it should have determined the correct version for you automatically."
  },
  {
    "objectID": "1_3_working-with-data_presentation.html#getting-packages-ready",
    "href": "1_3_working-with-data_presentation.html#getting-packages-ready",
    "title": "R Faculty Workshop",
    "section": "Getting packages ready",
    "text": "Getting packages ready\n\n# install external packages if you don't already have them\n\n# install.packages(c(\"tidyverse\", \"corrplot\",\"effectsize\", \"lme4\", \"lmerTest))\n\nThen you can activate the packages with the `library() function.\n\nlibrary(tidyverse)\nlibrary(effectsize)\nlibrary(corrplot)\nlibrary(lme4)"
  },
  {
    "objectID": "1_3_working-with-data_presentation.html#importing-data",
    "href": "1_3_working-with-data_presentation.html#importing-data",
    "title": "R Faculty Workshop",
    "section": "Importing data",
    "text": "Importing data\n\ntriplett_data &lt;- read_csv(\"triplett_data.csv\")\n\n# no output, but check your Global Environment\n\n\n# if your data was in a subdirectory...\n\ntriplett_data &lt;- read_csv(\"data_raw/triplett_data.csv\")"
  },
  {
    "objectID": "1_3_working-with-data_presentation.html#data-cleaning",
    "href": "1_3_working-with-data_presentation.html#data-cleaning",
    "title": "R Faculty Workshop",
    "section": "Data cleaning",
    "text": "Data cleaning\ntidyverse’s dplyr and tidyr packages contain some of the most useful functions for common data cleaning tasks:\n\nselect()\nfilter()\nmutate()\npivot_longer() and pivot_wider()"
  },
  {
    "objectID": "1_3_working-with-data_presentation.html#data-exploration",
    "href": "1_3_working-with-data_presentation.html#data-exploration",
    "title": "R Faculty Workshop",
    "section": "Data exploration",
    "text": "Data exploration"
  },
  {
    "objectID": "1_3_working-with-data_presentation.html#data-visualization",
    "href": "1_3_working-with-data_presentation.html#data-visualization",
    "title": "R Faculty Workshop",
    "section": "Data Visualization",
    "text": "Data Visualization"
  },
  {
    "objectID": "1_3_working-with-data_presentation.html#data-analysis",
    "href": "1_3_working-with-data_presentation.html#data-analysis",
    "title": "R Faculty Workshop",
    "section": "Data Analysis",
    "text": "Data Analysis"
  },
  {
    "objectID": "1_3_working-with-data.html",
    "href": "1_3_working-with-data.html",
    "title": "Working with data",
    "section": "",
    "text": "Start a new Project\n\n\n\nIn RStudio, click:\nFile &gt; New Project &gt; New Directory &gt; New Project\nOnce you have created the Project, save these files into your Project folder:\n\n triplett_analysis.R\n triplett_data.csv\n\nBack in RStudio you should see those files appear in the Files pane in the bottom-right. Click triplett_analysis.R to open that code file in the Editor pane.\n\n\n\n\n\n\n\n\nTriplett (1898)\n\n\n\nThe data we’re working with here is from Norman Triplett’s 1898 study of social facilitation, in which children played a game winding a flag around a track as fast as they could either alone or in competition with another child.\n\n\nI made a version you can play on your computer here.\n\n\n\n\nR can access your entire filesystem, so you can access and create files anywhere on your hard drive. It can be a bit tedious to type explicit complete file paths every time you need to read or write a file, however. E.g.:\n\"/Users/robertbrotherton/Documents/r-workshop/triplett_data.csv\"\nAnother big drawback is that if you share your code for someone else to run on their own computer, the filepaths will not work, since their folder will likely have different names.\nProjects help to overcome these kinds of issues. When working in a project, the ‘working directory’ is the Project’s folder.\n\n# check your current working directory\ngetwd()\n\n[1] \"/Users/robertbrotherton/Documents/r-workshop\"\n\n# should be your project folder\n\nWhenever you use a function that requires you to specify a filename, the function will be looking in that directory. So you can type:\n\nread_csv(file = \"triplett_data.csv\")\n\n…and if the file is in your Project folder it will be found. And if someone else runs the code on their computer, the file will be found as long as it is in their Project folder.\n\n\n\nOne of the strengths of R as a language for data analysis is its ecosystem of additional packages that make common tasks easier and code more eloquent. For the demonstrations here we’ll lean heavily into the tidyverse ecosystem. We’ll also use a few helpful functions from other packages.\nThe packages will need to be installed once, if they aren’t already on your system. Once you have installed them, I recommend turning that code into a comment so it doesn’t get executed again by accident.\n\n# install external packages if you don't already have them\n\n# install.packages(c(\"tidyverse\", \"corrplot\",\"effectsize\", \"lme4\", \"lmerTest))\n\nThen you can activate the packages with the `library() function.\n\nlibrary(tidyverse)\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.4     ✔ readr     2.1.5\n✔ forcats   1.0.0     ✔ stringr   1.5.1\n✔ ggplot2   3.5.1     ✔ tibble    3.2.1\n✔ lubridate 1.9.4     ✔ tidyr     1.3.1\n✔ purrr     1.0.4     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\nlibrary(effectsize)\nlibrary(corrplot)\n\ncorrplot 0.95 loaded\n\nlibrary(lme4)\n\nLoading required package: Matrix\n\nAttaching package: 'Matrix'\n\nThe following objects are masked from 'package:tidyr':\n\n    expand, pack, unpack\n\n\n\n\n\nR has a built-in function to read data from a .csv (comma-separated values) file like the one you downloaded: read.csv(). It works perfectly fine. However the tidyverse package readr has it’s own read_csv() function. In practice, they will give identical results, however I prefer to use the readr::read_csv since it gives some useful information when you run it.\n\ntriplett_data &lt;- read_csv(\"triplett_data.csv\")\n\n# no output, but check your Global Environment\n\n\n\nRows: 40 Columns: 12\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (4): subject, gender, group, classification\ndbl (8): age, alone_0, competition_1, alone_1, competition_2, alone_2, compe...\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\nThe raw comma-separated-values data get interpreted as a data.frame object that exists in R’s memory with the name triplett_data. You can click its name in your Global Environment to inspect it.\nNote that as a data analysis project becomes more complicate it may be useful to keep data files in a subdirectory of the Project folder. If your data was inside a folder named data_raw inside your main Project folder, for example, you would change the file argument to reflect that path:\n\n# if your data was in a subdirectory...\n\ntriplett_data &lt;- read_csv(\"data_raw/triplett_data.csv\")\n\n\n\nR can import (and write) many other data types, should the need arise.\n\n# Stata\nhaven::read_stata(\"stata_file.dta\")\n\n# SPSS\nhaven::read_spss(\"spss_file.sav\")\n\n# SAS\nhaven::read_sas(\"sas_file.sas\")\n\n# Excel\nreadxl::read_excel(\"excel_file.xlsx\", sheet = \"sheet name\")\n\n\n\n\n\ntidyverse’s dplyr and tidyr packages contain some of the most useful functions for common data cleaning tasks:\n\nselect()\nfilter()\nmutate()\npivot_longer() and pivot_wider()\n\n\n\nSometimes your raw data file has more columns that you need. dplyr’s select() function lets you choose which columns you want by typing their names with commas between. No need for quotation marks.\n\ntriplett_data |&gt; \n  select(subject, age, gender)\n\n# you can also rename as you select\ntriplett_data |&gt; \n  select(participant = subject, age, gender)\n\nTo drop a column, you can put a minus sign in front of its name. Other columns will be kept.\n\ntriplett_data |&gt; \n  select(-classification, -gender)\n\ndplyr has some helper functions to select columns as well, like starts_with(), contains().\n\ntriplett_data |&gt; \n  select(subject, contains(\"_1\")) # get each subject's first trials\n\n# try selecting just the \"competition\" trial columns\n\n\n\n\nselect() allows you to pick which columns you want; filter() allows you to pick which rows. Inside the function, you articulate a condition which can either be TRUE or FALSE. Each row will be checked, and those for which the condition is TRUE will be retained while those for which it is FALSE are dropped.\n\n# rows which meet the filter condition are kept\n# rows which don't are dropped\n\ntriplett_data_subset &lt;- triplett_data |&gt; \n  filter(group == \"A\") # subset the dataframe keeping only Group A\n\nYou can also specify multiple conditions as necessary. All conditions must evaluate to TRUE for a row to be retained.\n\n# keep only children 10 or older in Group A\n\ntriplett_data_subset &lt;- triplett_data |&gt; \n  filter(group == \"A\", age &gt;= 10)\n\n\n\n\nThe dplyr function mutate() creates new columns or modifies existing columns.\nThe general syntax is to specify the name of the column you want to create or modify, then an equals sign, then the operation which will compute the new values for that column. This will often be a function of existing variables, which you can refer to by name with no quotation marks. You can mutate more than one column at a time by separating the arguments with a comma.\n\n\n\ntriplett_data &lt;- triplett_data |&gt; \n  mutate(gender = factor(gender),\n         group = factor(group))\n\n\n\n\n\ntriplett_data_recoded &lt;- triplett_data |&gt; \n  mutate(alone_mean = rowMeans(across(contains(\"alone\"))))\n\n# produces NAs for some participants! oh no! why? can you fix it?\n\n\ntriplett_data_recoded &lt;- triplett_data |&gt; \n  mutate(alone_mean = rowMeans(across(contains(\"alone\")), na.rm = TRUE))\n\n# can you add code to get the mean competition score, and a difference score?\n\n\ntriplett_data_recoded &lt;- triplett_data |&gt; \n  mutate(alone_mean = rowMeans(across(contains(\"alone\")), na.rm = TRUE),\n         competition_mean = rowMeans(across(contains(\"competition\")), na.rm = TRUE),\n         diff = competition_mean - alone_mean)\n\n\n\n\nWhat if you need to create a new variable which differs depending on the value of an existing variable? case_when() allows us to articulate a set of conditions, and what value to assign when the condition is met.\n\ntriplett_data_recoded &lt;- triplett_data_recoded |&gt; \n  mutate(effect = case_when(\n    diff &lt; -sd(diff) ~ \"improved\",\n    diff &gt; sd(diff) ~ \"impaired\",\n    TRUE ~ \"no difference\"\n  ))\n\nConditions are checked in order. The final step, TRUE ~ \"no difference\" is the default value that will be assigned to any row which has not met any of the prior conditions (because TRUE will be true of every row).\n\n\n\n\nSometimes it is useful to reshape data from wide to long format. The Triplett data in its initial .csv form is wide; each row contains multiple observations from a single participant. It will be helpful to have a long version of this, in which each row corresponds to a single observation.\n\ntriplett_long &lt;- triplett_data |&gt; \n  pivot_longer(contains(c(\"alone\", \"competition\")),\n               names_to = c(\"condition\", \"trial\"),\n               names_sep = \"_\",\n               values_to = \"performance\")\n\n\n\n\nOnce you have a new version of your data, you may wish to save it as a new file for easy sharing or reuse.\nOne option is to save it as an R data file. Obviously this is specialized for R and cannot be opened in Excel, for example.\n\nsaveRDS(triplett_long, \"triplett_long.RDS\")\n\nAnother option is to save it as a .csv file.\n\nreadr::write_csv(triplett_long, \"triplett_long.csv\")\n\n\n\n\n\n\n\nA quick and easy way to get some summary statistics for a data.frame is to use the summary() function.\n\ntriplett_data_recoded |&gt; \n  select(age, gender, group, alone_mean, competition_mean, diff) |&gt; \n  summary()\n\n      age        gender group    alone_mean    competition_mean\n Min.   : 8.00   f:26   A:20   Min.   :27.67   Min.   :27.20   \n 1st Qu.:10.75   m:14   B:20   1st Qu.:34.04   1st Qu.:33.05   \n Median :11.00                 Median :39.22   Median :36.98   \n Mean   :11.50                 Mean   :39.48   Mean   :37.41   \n 3rd Qu.:13.00                 3rd Qu.:44.62   3rd Qu.:41.43   \n Max.   :17.00                 Max.   :57.13   Max.   :50.73   \n      diff        \n Min.   :-6.4000  \n 1st Qu.:-4.1250  \n Median :-1.7417  \n Mean   :-2.0694  \n 3rd Qu.: 0.1625  \n Max.   : 2.0000  \n\n\n\n\n\ntriplett_data_recoded |&gt; \n  count(gender, classification) |&gt; \n  mutate(prop = n / sum(n), .by = gender)\n\n\n\n\n\ngender\nclassification\nn\nprop\n\n\n\n\nf\nlittle affected\n6\n0.2307692\n\n\nf\nstimulated adversely\n5\n0.1923077\n\n\nf\nstimulated positively\n15\n0.5769231\n\n\nm\nlittle affected\n4\n0.2857143\n\n\nm\nstimulated adversely\n5\n0.3571429\n\n\nm\nstimulated positively\n5\n0.3571429\n\n\n\n\n\n\n\n\n\n\nThe dplyr function summarize() is a powerful way of producing summary statistics from a data.frame. Its syntax is similar to that of mutate(): you specify the name of a column you would like to create, then an equals sign, then the operation(s) that will compute the desired value, e.g. mean_score = mean(scores).\nThe difference between summarize() and mutate() is that mutate() modifies the full dataset, whereas summarize() produces a new data.frame by reducing the values in the dataset down to a single summary value such as a mean, standard deviation, or whatever other summary statistic you might like to compute.\n\ntriplett_data_recoded |&gt; \n  summarize(n = n(), \n            mean_diff = mean(diff),\n            sd_diff = sd(diff),\n            min = min(diff),\n            max = max(diff),\n            range = max - min)\n\n\n\n\n\nn\nmean_diff\nsd_diff\nmin\nmax\nrange\n\n\n\n\n40\n-2.069417\n2.475617\n-6.4\n2\n8.4\n\n\n\n\n\n\n\n\n\nsummarize()’s superpower is it’s special argument, .by. This lets us specify a grouping variable. Whatever summary statistics you ask for will be computed separately for each level of the grouping variable.\n\ntriplett_data_recoded |&gt; \n  summarize(n = n(), \n            mean_diff = mean(diff),\n            sd_diff = sd(diff),\n            range = max(diff) - min(diff),\n            .by = gender)\n\n\n\n\n\ngender\nn\nmean_diff\nsd_diff\nrange\n\n\n\n\nf\n26\n-2.631795\n2.602639\n8.40\n\n\nm\n14\n-1.025000\n1.884777\n6.05\n\n\n\n\n\n# can you summarize by one of the other categorical variables?\n\n\n\n\nYou can have any number of grouping variables; just collect them together with the c() function when using the .by argument. Summary statistics will be produced for all combination of the variables that you specify.\n\ncomplex_summary &lt;- triplett_long |&gt; \n  summarize(average = mean(performance),\n            .by = c(classification, condition, trial, group))\n\n\n\n\n\n\n\nclassification\ncondition\ntrial\ngroup\naverage\n\n\n\n\nstimulated positively\nalone\n0\nA\n47.49\n\n\nstimulated positively\nalone\n1\nA\n42.60\n\n\nstimulated positively\nalone\n2\nA\n38.42\n\n\nstimulated positively\nalone\n3\nA\nNA\n\n\nstimulated positively\ncompetition\n1\nA\n41.88\n\n\nstimulated positively\ncompetition\n2\nA\n39.28\n\n\n\n\n\n\n\n\n\n\n\n\nAs usual, there are many ways of visualizing data in R, but the most widely used and flexible is the ggplot2 package. This package is part of the tidyverse.\nThe “gg” in “ggplot” refers to the “grammar of graphics”. ggplot works by layering, using the + symbol.\n\n# ggplot syntax\n\nmy_data |&gt; \n  \n# 1. start with data and aesthetic mappings\nggplot(aes(x = x_var, y = y_var)) +\n\n# 2. add geometry (e.g. points, columns, lines)\n  geom_point() +\n\n# 3. add more layers geometry if needed\n  geom_smooth(method = \"lm\") +\n\n# 4. customize labels, themes, etc.\n  labs(title = \"My Plot\", x = \"X Label\", y = \"Y Label\") +\n  theme_minimal()\n\n\n\n\ntriplett_data_recoded |&gt; \n  ggplot(aes(x = diff)) + # only x aesthetic is required for histogram\n  geom_histogram(bins = 10)\n\n\n\n\n\n\n\n\n\n\n\nTo change the deafult look of ggplot’s graphs you can modify many elements within the theme() function.\n\ntheme_apa &lt;- theme(\n  panel.background = element_blank(),\n  axis.line = element_line(),\n  axis.text = element_text(size = 20),\n  axis.title = element_text(size = 22),\n  legend.text = element_text(size = 20),\n  legend.title = element_text(size = 22)\n)\n\nThis theme_apa object can then be added as a layer to subsequent graphs.\n\ntriplett_data_recoded |&gt; \n  ggplot(aes(x = diff)) + # only x aesthetic is required for histogram\n  geom_histogram(bins = 10, color = \"white\") +\n  theme_apa\n\n\n\n\n\n\n\n\n\n\n\nFor a scatterplot, we would specify both x and y aesthetics, and use geom_point() for the geometry.\n\ntriplett_data_recoded |&gt; \n  ggplot(aes(x = age, y = alone_0)) +\n  geom_point(position = \"jitter\") +\n  theme_apa\n\n\n\n\n\n\n\n\n\n\n\nThere are other aesthetics beyond x and y. We can also map data to a color or fill aesthetic, for example. Let’s also add fit lines using the geom_smooth() geometry, specifying the method used to compute the lines with method = \"lm\" (for “linear model”). Notice that we get two different lines, distinguished according to the color aesthetic. Since we specified that in the initial ggplot(aes(...)) part, it applies to all subsequent layers of the plot.\n\ntriplett_data_recoded |&gt; \n  ggplot(aes(x = age, y = alone_0, color = gender)) +\n  geom_point() +\n  geom_smooth(method = \"lm\") +\n  theme_apa\n\n`geom_smooth()` using formula = 'y ~ x'\n\n\n\n\n\n\n\n\n\n\n\n\n\n\ntriplett_data |&gt; \n  ggplot(aes(x = factor(age), y = alone_0, color = gender)) +\n  geom_boxplot() +\n  theme_apa\n\n\n\n\n\n\n\n\nFor more complex visuals, it can be useful to combine summarize() for computing summary stats with ggplot for visualizing the resulting results.\n\ntriplett_long |&gt; \n  summarize(performance = mean(performance, na.rm = TRUE), \n            .by = c(trial, condition)) |&gt; \n  ggplot(aes(x = trial, y = performance, fill = condition)) +\n  geom_col(position = \"dodge\") +\n  theme_apa\n\n\n\n\n\n\n\n\n\n\n\n\nI’ll run show some basic–and some more advanced–analyses here. I won’t dwell on the details, just show the basic format. Each function has its own help documentation should you need to refer to it.\n\n\n\ncor.test(x = triplett_data$age, y = triplett_data$alone_0)\n\n\n    Pearson's product-moment correlation\n\ndata:  triplett_data$age and triplett_data$alone_0\nt = -3.2537, df = 38, p-value = 0.002394\nalternative hypothesis: true correlation is not equal to 0\n95 percent confidence interval:\n -0.6794952 -0.1817032\nsample estimates:\n       cor \n-0.4667911 \n\n\n\n\n\n\ntriplett_data |&gt; \n  select(contains(\"alone\"), contains(\"competition\")) |&gt; \n  cor(use = \"pairwise\") |&gt; \n  corrplot::corrplot(method = 'shade')\n\n\n\n\n\n\n\n\n\n\n\n\n# are the genders differently distributed among Triplett's classification categories\n\nchisq.test(x = triplett_data_recoded$classification,\n           y = triplett_data_recoded$gender)\n\nWarning in chisq.test(x = triplett_data_recoded$classification, y =\ntriplett_data_recoded$gender): Chi-squared approximation may be incorrect\n\n\n\n    Pearson's Chi-squared test\n\ndata:  triplett_data_recoded$classification and triplett_data_recoded$gender\nX-squared = 1.978, df = 2, p-value = 0.3719\n\n\n\n\n\n\n\nR has a t.test() function built in. When the DV is in one column and the IV grouping variable is in another, we can specify a formula using those column names in the generic format DV ~ IV (as in, ‘compare scores on the DV by the groups of the IV’).\n\n# is there a difference between the genders?\n# t.test takes a 'formula' in the form 'DV ~ IV'\n\nt.test(alone_0 ~ gender, data = triplett_data)\n\n\n    Welch Two Sample t-test\n\ndata:  alone_0 by gender\nt = 2.9599, df = 31.645, p-value = 0.005788\nalternative hypothesis: true difference in means between group f and group m is not equal to 0\n95 percent confidence interval:\n  2.315627 12.551406\nsample estimates:\nmean in group f mean in group m \n       45.41923        37.98571 \n\n\n\n\n\nFor a related-samples t-test we would generally need wide-format data, where each row of data contains two columns\n\nt.test(x = triplett_data_recoded$alone_mean,\n       y = triplett_data_recoded$competition_mean,\n       paired = TRUE)\n\n\n    Paired t-test\n\ndata:  triplett_data_recoded$alone_mean and triplett_data_recoded$competition_mean\nt = 5.2868, df = 39, p-value = 5.048e-06\nalternative hypothesis: true mean difference is not equal to 0\n95 percent confidence interval:\n 1.277676 2.861157\nsample estimates:\nmean difference \n       2.069417 \n\n\n\n\n\n\neffectsize::cohens_d(alone_0 ~ gender, data = triplett_data)\n\n\n\n\n\nCohens_d\nCI\nCI_low\nCI_high\n\n\n\n\n0.9234365\n0.95\n0.2360446\n1.599793\n\n\n\n\n\neffectsize::cohens_d(x = triplett_data_recoded$alone_mean,\n                     y = triplett_data_recoded$competition_mean,\n                     paired = TRUE)\n\nFor paired samples, 'repeated_measures_d()' provides more options.\n\n\n\n\n\n\nCohens_d\nCI\nCI_low\nCI_high\n\n\n\n\n0.8359196\n0.95\n0.4710662\n1.192793\n\n\n\n\n\n\n\n\n\n\n\n\nThe aov() function computes an ANOVA model. It accepts a formula in the form DV ~ IV, just like the independent-samples t.test() example above.\n\n# aov expects a 'formula' in the form 'DV ~ IV'\n\naov(diff ~ classification, data = triplett_data_recoded)\n\nCall:\n   aov(formula = diff ~ classification, data = triplett_data_recoded)\n\nTerms:\n                classification Residuals\nSum of Squares       139.31890  99.69957\nDeg. of Freedom              2        37\n\nResidual standard error: 1.641518\nEstimated effects may be unbalanced\n\n\nSometimes, like with aov(), the function that computes a model doesn’t tell us everything we typically want to know about that model. It is often useful to assign the model to a name, and then ask for a summary of the model:\n\n# aov doesn't print useful output by itself, so assign to a name\n\nanova &lt;- aov(diff ~ classification, data = triplett_data_recoded)\n\n# then get a summary\n\nsummary(anova)\n\n               Df Sum Sq Mean Sq F value   Pr(&gt;F)    \nclassification  2  139.3   69.66   25.85 9.44e-08 ***\nResiduals      37   99.7    2.69                     \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\n\n\n\nThe aov() and summary() approach also works for within-participants designs. We just need to articulate the Error() term, using a column which uniquely identifies participants, and the grouping variable column.\n\n# related-samples ANOVA requires Error term, using columns\n# for participant IDs and the IV grouping variable\n\naov(performance ~ condition + Error(subject/condition), data = triplett_long) |&gt; \n  summary()\n\n\nError: subject\n          Df Sum Sq Mean Sq F value Pr(&gt;F)\ncondition  1     22   21.85   0.092  0.763\nResiduals 38   8993  236.65               \n\nError: subject:condition\n          Df Sum Sq Mean Sq F value   Pr(&gt;F)    \ncondition  1  242.2   242.2   27.84 5.22e-06 ***\nResiduals 39  339.3     8.7                     \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nError: Within\n           Df Sum Sq Mean Sq F value Pr(&gt;F)\nResiduals 161   2346   14.57               \n\n\n\n\n\n\n\n# the lm (linear model) function accepts a formula like t.test and aov\n# we can add as many predictors as we want with\n\nlm(diff ~ age + gender + group, data = triplett_data_recoded) |&gt; \n  summary()\n\n\nCall:\nlm(formula = diff ~ age + gender + group, data = triplett_data_recoded)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-3.5875 -1.7558 -0.0978  1.5994  4.9705 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)  \n(Intercept)  -5.0325     2.5089  -2.006   0.0524 .\nage           0.2385     0.2184   1.092   0.2821  \ngenderm       1.4309     0.8163   1.753   0.0881 .\ngroupB       -0.5619     0.7853  -0.716   0.4789  \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 2.398 on 36 degrees of freedom\nMultiple R-squared:  0.1342,    Adjusted R-squared:  0.06209 \nF-statistic: 1.861 on 3 and 36 DF,  p-value: 0.1537\n\n\n\n\n\n\nmixed_model &lt;- lme4::lmer(\n  performance ~ condition * age + group + (1 | subject), \n  data = triplett_long\n  )\n\nsummary(mixed_model)\n\nLinear mixed model fit by REML ['lmerMod']\nFormula: performance ~ condition * age + group + (1 | subject)\n   Data: triplett_long\n\nREML criterion at convergence: 1403\n\nScaled residuals: \n    Min      1Q  Median      3Q     Max \n-2.1757 -0.6269 -0.1108  0.4602  3.4458 \n\nRandom effects:\n Groups   Name        Variance Std.Dev.\n subject  (Intercept) 26.52    5.150   \n Residual             13.44    3.667   \nNumber of obs: 241, groups:  subject, 40\n\nFixed effects:\n                         Estimate Std. Error t value\n(Intercept)               61.8434     5.7664  10.725\nconditioncompetition      -4.6886     3.1964  -1.467\nage                       -1.9923     0.5002  -3.983\ngroupB                     1.1393     1.7148   0.664\nconditioncompetition:age   0.2287     0.2753   0.831\n\nCorrelation of Fixed Effects:\n            (Intr) cndtnc age    groupB\ncndtncmpttn -0.236                     \nage         -0.977  0.230              \ngroupB      -0.013  0.005 -0.138       \ncndtncmptt:  0.232 -0.988 -0.233  0.002\n\n\nlmr4::lmer() doesn’t give p-values (because they require some additional assumptions). The package lmerTest has wraps lmer() with some additional computation of p-values.\n\nmixed_model &lt;- lmerTest::lmer(\n  performance ~ condition * age + group + (1 | subject), \n  data = triplett_long\n  )\n\nsummary(mixed_model)\n\nLinear mixed model fit by REML. t-tests use Satterthwaite's method [\nlmerModLmerTest]\nFormula: performance ~ condition * age + group + (1 | subject)\n   Data: triplett_long\n\nREML criterion at convergence: 1403\n\nScaled residuals: \n    Min      1Q  Median      3Q     Max \n-2.1757 -0.6269 -0.1108  0.4602  3.4458 \n\nRandom effects:\n Groups   Name        Variance Std.Dev.\n subject  (Intercept) 26.52    5.150   \n Residual             13.44    3.667   \nNumber of obs: 241, groups:  subject, 40\n\nFixed effects:\n                         Estimate Std. Error       df t value Pr(&gt;|t|)    \n(Intercept)               61.8434     5.7664  41.4686  10.725 1.57e-13 ***\nconditioncompetition      -4.6886     3.1964 199.8308  -1.467  0.14399    \nage                       -1.9923     0.5002  41.3136  -3.983  0.00027 ***\ngroupB                     1.1393     1.7148  37.1406   0.664  0.51056    \nconditioncompetition:age   0.2287     0.2753 199.8510   0.831  0.40713    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nCorrelation of Fixed Effects:\n            (Intr) cndtnc age    groupB\ncndtncmpttn -0.236                     \nage         -0.977  0.230              \ngroupB      -0.013  0.005 -0.138       \ncndtncmptt:  0.232 -0.988 -0.233  0.002\n\n\n\n\n\n\nCode\ntriplett_long |&gt; \n  ggplot(aes(x = trial, y = performance, group = subject, color = condition)) +\n  geom_line(alpha = 0.3) +\n  stat_summary(aes(group = condition), fun = mean, geom = \"line\", linewidth = 1.2, color = \"black\") +\n  facet_wrap(~condition) +\n  labs(title = \"Performance over Trials by Condition\",\n       x = \"Trial\", y = \"Reeling Speed\",\n       caption = \"Color lines = individual subjects; bold line = group mean\") +\n  theme_apa\n\n\nWarning: Removed 39 rows containing non-finite outside the scale range\n(`stat_summary()`).\n\n\nWarning: Removed 19 rows containing missing values or values outside the scale range\n(`geom_line()`).",
    "crumbs": [
      "Day 1: Intro to R",
      "Working with data"
    ]
  },
  {
    "objectID": "1_3_working-with-data.html#getting-packages-ready",
    "href": "1_3_working-with-data.html#getting-packages-ready",
    "title": "Working with data",
    "section": "",
    "text": "One of the strengths of R as a language for data analysis is its ecosystem of additional packages that make common tasks easier and code more eloquent. For the demonstrations here we’ll lean heavily into the tidyverse ecosystem. We’ll also use a few helpful functions from other packages.\nThe packages will need to be installed once, if they aren’t already on your system. Once you have installed them, I recommend turning that code into a comment so it doesn’t get executed again by accident.\n\n# install external packages if you don't already have them\n\n# install.packages(c(\"tidyverse\", \"corrplot\",\"effectsize\", \"lme4\", \"lmerTest))\n\nThen you can activate the packages with the `library() function.\n\nlibrary(tidyverse)\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.4     ✔ readr     2.1.5\n✔ forcats   1.0.0     ✔ stringr   1.5.1\n✔ ggplot2   3.5.1     ✔ tibble    3.2.1\n✔ lubridate 1.9.4     ✔ tidyr     1.3.1\n✔ purrr     1.0.4     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\nlibrary(effectsize)\nlibrary(corrplot)\n\ncorrplot 0.95 loaded\n\nlibrary(lme4)\n\nLoading required package: Matrix\n\nAttaching package: 'Matrix'\n\nThe following objects are masked from 'package:tidyr':\n\n    expand, pack, unpack",
    "crumbs": [
      "Day 1: Intro to R",
      "Working with data"
    ]
  },
  {
    "objectID": "1_3_working-with-data.html#importing-data",
    "href": "1_3_working-with-data.html#importing-data",
    "title": "Working with data",
    "section": "",
    "text": "R has a built-in function to read data from a .csv (comma-separated values) file like the one you downloaded: read.csv(). It works perfectly fine. However the tidyverse package readr has it’s own read_csv() function. In practice, they will give identical results, however I prefer to use the readr::read_csv since it gives some useful information when you run it.\n\ntriplett_data &lt;- read_csv(\"triplett_data.csv\")\n\n# no output, but check your Global Environment\n\n\n\nRows: 40 Columns: 12\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (4): subject, gender, group, classification\ndbl (8): age, alone_0, competition_1, alone_1, competition_2, alone_2, compe...\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\nThe raw comma-separated-values data get interpreted as a data.frame object that exists in R’s memory with the name triplett_data. You can click its name in your Global Environment to inspect it.\nNote that as a data analysis project becomes more complicate it may be useful to keep data files in a subdirectory of the Project folder. If your data was inside a folder named data_raw inside your main Project folder, for example, you would change the file argument to reflect that path:\n\n# if your data was in a subdirectory...\n\ntriplett_data &lt;- read_csv(\"data_raw/triplett_data.csv\")\n\n\n\nR can import (and write) many other data types, should the need arise.\n\n# Stata\nhaven::read_stata(\"stata_file.dta\")\n\n# SPSS\nhaven::read_spss(\"spss_file.sav\")\n\n# SAS\nhaven::read_sas(\"sas_file.sas\")\n\n# Excel\nreadxl::read_excel(\"excel_file.xlsx\", sheet = \"sheet name\")",
    "crumbs": [
      "Day 1: Intro to R",
      "Working with data"
    ]
  },
  {
    "objectID": "1_3_working-with-data.html#data-cleaning",
    "href": "1_3_working-with-data.html#data-cleaning",
    "title": "Working with data",
    "section": "",
    "text": "tidyverse’s dplyr and tidyr packages contain some of the most useful functions for common data cleaning tasks:\n\nselect()\nfilter()\nmutate()\npivot_longer() and pivot_wider()\n\n\n\nSometimes your raw data file has more columns that you need. dplyr’s select() function lets you choose which columns you want by typing their names with commas between. No need for quotation marks.\n\ntriplett_data |&gt; \n  select(subject, age, gender)\n\n# you can also rename as you select\ntriplett_data |&gt; \n  select(participant = subject, age, gender)\n\nTo drop a column, you can put a minus sign in front of its name. Other columns will be kept.\n\ntriplett_data |&gt; \n  select(-classification, -gender)\n\ndplyr has some helper functions to select columns as well, like starts_with(), contains().\n\ntriplett_data |&gt; \n  select(subject, contains(\"_1\")) # get each subject's first trials\n\n# try selecting just the \"competition\" trial columns\n\n\n\n\nselect() allows you to pick which columns you want; filter() allows you to pick which rows. Inside the function, you articulate a condition which can either be TRUE or FALSE. Each row will be checked, and those for which the condition is TRUE will be retained while those for which it is FALSE are dropped.\n\n# rows which meet the filter condition are kept\n# rows which don't are dropped\n\ntriplett_data_subset &lt;- triplett_data |&gt; \n  filter(group == \"A\") # subset the dataframe keeping only Group A\n\nYou can also specify multiple conditions as necessary. All conditions must evaluate to TRUE for a row to be retained.\n\n# keep only children 10 or older in Group A\n\ntriplett_data_subset &lt;- triplett_data |&gt; \n  filter(group == \"A\", age &gt;= 10)\n\n\n\n\nThe dplyr function mutate() creates new columns or modifies existing columns.\nThe general syntax is to specify the name of the column you want to create or modify, then an equals sign, then the operation which will compute the new values for that column. This will often be a function of existing variables, which you can refer to by name with no quotation marks. You can mutate more than one column at a time by separating the arguments with a comma.\n\n\n\ntriplett_data &lt;- triplett_data |&gt; \n  mutate(gender = factor(gender),\n         group = factor(group))\n\n\n\n\n\ntriplett_data_recoded &lt;- triplett_data |&gt; \n  mutate(alone_mean = rowMeans(across(contains(\"alone\"))))\n\n# produces NAs for some participants! oh no! why? can you fix it?\n\n\ntriplett_data_recoded &lt;- triplett_data |&gt; \n  mutate(alone_mean = rowMeans(across(contains(\"alone\")), na.rm = TRUE))\n\n# can you add code to get the mean competition score, and a difference score?\n\n\ntriplett_data_recoded &lt;- triplett_data |&gt; \n  mutate(alone_mean = rowMeans(across(contains(\"alone\")), na.rm = TRUE),\n         competition_mean = rowMeans(across(contains(\"competition\")), na.rm = TRUE),\n         diff = competition_mean - alone_mean)\n\n\n\n\nWhat if you need to create a new variable which differs depending on the value of an existing variable? case_when() allows us to articulate a set of conditions, and what value to assign when the condition is met.\n\ntriplett_data_recoded &lt;- triplett_data_recoded |&gt; \n  mutate(effect = case_when(\n    diff &lt; -sd(diff) ~ \"improved\",\n    diff &gt; sd(diff) ~ \"impaired\",\n    TRUE ~ \"no difference\"\n  ))\n\nConditions are checked in order. The final step, TRUE ~ \"no difference\" is the default value that will be assigned to any row which has not met any of the prior conditions (because TRUE will be true of every row).\n\n\n\n\nSometimes it is useful to reshape data from wide to long format. The Triplett data in its initial .csv form is wide; each row contains multiple observations from a single participant. It will be helpful to have a long version of this, in which each row corresponds to a single observation.\n\ntriplett_long &lt;- triplett_data |&gt; \n  pivot_longer(contains(c(\"alone\", \"competition\")),\n               names_to = c(\"condition\", \"trial\"),\n               names_sep = \"_\",\n               values_to = \"performance\")\n\n\n\n\nOnce you have a new version of your data, you may wish to save it as a new file for easy sharing or reuse.\nOne option is to save it as an R data file. Obviously this is specialized for R and cannot be opened in Excel, for example.\n\nsaveRDS(triplett_long, \"triplett_long.RDS\")\n\nAnother option is to save it as a .csv file.\n\nreadr::write_csv(triplett_long, \"triplett_long.csv\")",
    "crumbs": [
      "Day 1: Intro to R",
      "Working with data"
    ]
  },
  {
    "objectID": "1_3_working-with-data.html#data-exploration",
    "href": "1_3_working-with-data.html#data-exploration",
    "title": "Working with data",
    "section": "",
    "text": "A quick and easy way to get some summary statistics for a data.frame is to use the summary() function.\n\ntriplett_data_recoded |&gt; \n  select(age, gender, group, alone_mean, competition_mean, diff) |&gt; \n  summary()\n\n      age        gender group    alone_mean    competition_mean\n Min.   : 8.00   f:26   A:20   Min.   :27.67   Min.   :27.20   \n 1st Qu.:10.75   m:14   B:20   1st Qu.:34.04   1st Qu.:33.05   \n Median :11.00                 Median :39.22   Median :36.98   \n Mean   :11.50                 Mean   :39.48   Mean   :37.41   \n 3rd Qu.:13.00                 3rd Qu.:44.62   3rd Qu.:41.43   \n Max.   :17.00                 Max.   :57.13   Max.   :50.73   \n      diff        \n Min.   :-6.4000  \n 1st Qu.:-4.1250  \n Median :-1.7417  \n Mean   :-2.0694  \n 3rd Qu.: 0.1625  \n Max.   : 2.0000  \n\n\n\n\n\ntriplett_data_recoded |&gt; \n  count(gender, classification) |&gt; \n  mutate(prop = n / sum(n), .by = gender)\n\n\n\n\n\ngender\nclassification\nn\nprop\n\n\n\n\nf\nlittle affected\n6\n0.2307692\n\n\nf\nstimulated adversely\n5\n0.1923077\n\n\nf\nstimulated positively\n15\n0.5769231\n\n\nm\nlittle affected\n4\n0.2857143\n\n\nm\nstimulated adversely\n5\n0.3571429\n\n\nm\nstimulated positively\n5\n0.3571429\n\n\n\n\n\n\n\n\n\n\nThe dplyr function summarize() is a powerful way of producing summary statistics from a data.frame. Its syntax is similar to that of mutate(): you specify the name of a column you would like to create, then an equals sign, then the operation(s) that will compute the desired value, e.g. mean_score = mean(scores).\nThe difference between summarize() and mutate() is that mutate() modifies the full dataset, whereas summarize() produces a new data.frame by reducing the values in the dataset down to a single summary value such as a mean, standard deviation, or whatever other summary statistic you might like to compute.\n\ntriplett_data_recoded |&gt; \n  summarize(n = n(), \n            mean_diff = mean(diff),\n            sd_diff = sd(diff),\n            min = min(diff),\n            max = max(diff),\n            range = max - min)\n\n\n\n\n\nn\nmean_diff\nsd_diff\nmin\nmax\nrange\n\n\n\n\n40\n-2.069417\n2.475617\n-6.4\n2\n8.4\n\n\n\n\n\n\n\n\n\nsummarize()’s superpower is it’s special argument, .by. This lets us specify a grouping variable. Whatever summary statistics you ask for will be computed separately for each level of the grouping variable.\n\ntriplett_data_recoded |&gt; \n  summarize(n = n(), \n            mean_diff = mean(diff),\n            sd_diff = sd(diff),\n            range = max(diff) - min(diff),\n            .by = gender)\n\n\n\n\n\ngender\nn\nmean_diff\nsd_diff\nrange\n\n\n\n\nf\n26\n-2.631795\n2.602639\n8.40\n\n\nm\n14\n-1.025000\n1.884777\n6.05\n\n\n\n\n\n# can you summarize by one of the other categorical variables?\n\n\n\n\nYou can have any number of grouping variables; just collect them together with the c() function when using the .by argument. Summary statistics will be produced for all combination of the variables that you specify.\n\ncomplex_summary &lt;- triplett_long |&gt; \n  summarize(average = mean(performance),\n            .by = c(classification, condition, trial, group))\n\n\n\n\n\n\n\nclassification\ncondition\ntrial\ngroup\naverage\n\n\n\n\nstimulated positively\nalone\n0\nA\n47.49\n\n\nstimulated positively\nalone\n1\nA\n42.60\n\n\nstimulated positively\nalone\n2\nA\n38.42\n\n\nstimulated positively\nalone\n3\nA\nNA\n\n\nstimulated positively\ncompetition\n1\nA\n41.88\n\n\nstimulated positively\ncompetition\n2\nA\n39.28",
    "crumbs": [
      "Day 1: Intro to R",
      "Working with data"
    ]
  },
  {
    "objectID": "1_3_working-with-data.html#data-visualization",
    "href": "1_3_working-with-data.html#data-visualization",
    "title": "Working with data",
    "section": "",
    "text": "As usual, there are many ways of visualizing data in R, but the most widely used and flexible is the ggplot2 package. This package is part of the tidyverse.\nThe “gg” in “ggplot” refers to the “grammar of graphics”. ggplot works by layering, using the + symbol.\n\n# ggplot syntax\n\nmy_data |&gt; \n  \n# 1. start with data and aesthetic mappings\nggplot(aes(x = x_var, y = y_var)) +\n\n# 2. add geometry (e.g. points, columns, lines)\n  geom_point() +\n\n# 3. add more layers geometry if needed\n  geom_smooth(method = \"lm\") +\n\n# 4. customize labels, themes, etc.\n  labs(title = \"My Plot\", x = \"X Label\", y = \"Y Label\") +\n  theme_minimal()\n\n\n\n\ntriplett_data_recoded |&gt; \n  ggplot(aes(x = diff)) + # only x aesthetic is required for histogram\n  geom_histogram(bins = 10)\n\n\n\n\n\n\n\n\n\n\n\nTo change the deafult look of ggplot’s graphs you can modify many elements within the theme() function.\n\ntheme_apa &lt;- theme(\n  panel.background = element_blank(),\n  axis.line = element_line(),\n  axis.text = element_text(size = 20),\n  axis.title = element_text(size = 22),\n  legend.text = element_text(size = 20),\n  legend.title = element_text(size = 22)\n)\n\nThis theme_apa object can then be added as a layer to subsequent graphs.\n\ntriplett_data_recoded |&gt; \n  ggplot(aes(x = diff)) + # only x aesthetic is required for histogram\n  geom_histogram(bins = 10, color = \"white\") +\n  theme_apa\n\n\n\n\n\n\n\n\n\n\n\nFor a scatterplot, we would specify both x and y aesthetics, and use geom_point() for the geometry.\n\ntriplett_data_recoded |&gt; \n  ggplot(aes(x = age, y = alone_0)) +\n  geom_point(position = \"jitter\") +\n  theme_apa\n\n\n\n\n\n\n\n\n\n\n\nThere are other aesthetics beyond x and y. We can also map data to a color or fill aesthetic, for example. Let’s also add fit lines using the geom_smooth() geometry, specifying the method used to compute the lines with method = \"lm\" (for “linear model”). Notice that we get two different lines, distinguished according to the color aesthetic. Since we specified that in the initial ggplot(aes(...)) part, it applies to all subsequent layers of the plot.\n\ntriplett_data_recoded |&gt; \n  ggplot(aes(x = age, y = alone_0, color = gender)) +\n  geom_point() +\n  geom_smooth(method = \"lm\") +\n  theme_apa\n\n`geom_smooth()` using formula = 'y ~ x'\n\n\n\n\n\n\n\n\n\n\n\n\n\n\ntriplett_data |&gt; \n  ggplot(aes(x = factor(age), y = alone_0, color = gender)) +\n  geom_boxplot() +\n  theme_apa\n\n\n\n\n\n\n\n\nFor more complex visuals, it can be useful to combine summarize() for computing summary stats with ggplot for visualizing the resulting results.\n\ntriplett_long |&gt; \n  summarize(performance = mean(performance, na.rm = TRUE), \n            .by = c(trial, condition)) |&gt; \n  ggplot(aes(x = trial, y = performance, fill = condition)) +\n  geom_col(position = \"dodge\") +\n  theme_apa",
    "crumbs": [
      "Day 1: Intro to R",
      "Working with data"
    ]
  },
  {
    "objectID": "1_3_working-with-data.html#data-analysis",
    "href": "1_3_working-with-data.html#data-analysis",
    "title": "Working with data",
    "section": "",
    "text": "I’ll run show some basic–and some more advanced–analyses here. I won’t dwell on the details, just show the basic format. Each function has its own help documentation should you need to refer to it.\n\n\n\ncor.test(x = triplett_data$age, y = triplett_data$alone_0)\n\n\n    Pearson's product-moment correlation\n\ndata:  triplett_data$age and triplett_data$alone_0\nt = -3.2537, df = 38, p-value = 0.002394\nalternative hypothesis: true correlation is not equal to 0\n95 percent confidence interval:\n -0.6794952 -0.1817032\nsample estimates:\n       cor \n-0.4667911 \n\n\n\n\n\n\ntriplett_data |&gt; \n  select(contains(\"alone\"), contains(\"competition\")) |&gt; \n  cor(use = \"pairwise\") |&gt; \n  corrplot::corrplot(method = 'shade')\n\n\n\n\n\n\n\n\n\n\n\n\n# are the genders differently distributed among Triplett's classification categories\n\nchisq.test(x = triplett_data_recoded$classification,\n           y = triplett_data_recoded$gender)\n\nWarning in chisq.test(x = triplett_data_recoded$classification, y =\ntriplett_data_recoded$gender): Chi-squared approximation may be incorrect\n\n\n\n    Pearson's Chi-squared test\n\ndata:  triplett_data_recoded$classification and triplett_data_recoded$gender\nX-squared = 1.978, df = 2, p-value = 0.3719\n\n\n\n\n\n\n\nR has a t.test() function built in. When the DV is in one column and the IV grouping variable is in another, we can specify a formula using those column names in the generic format DV ~ IV (as in, ‘compare scores on the DV by the groups of the IV’).\n\n# is there a difference between the genders?\n# t.test takes a 'formula' in the form 'DV ~ IV'\n\nt.test(alone_0 ~ gender, data = triplett_data)\n\n\n    Welch Two Sample t-test\n\ndata:  alone_0 by gender\nt = 2.9599, df = 31.645, p-value = 0.005788\nalternative hypothesis: true difference in means between group f and group m is not equal to 0\n95 percent confidence interval:\n  2.315627 12.551406\nsample estimates:\nmean in group f mean in group m \n       45.41923        37.98571 \n\n\n\n\n\nFor a related-samples t-test we would generally need wide-format data, where each row of data contains two columns\n\nt.test(x = triplett_data_recoded$alone_mean,\n       y = triplett_data_recoded$competition_mean,\n       paired = TRUE)\n\n\n    Paired t-test\n\ndata:  triplett_data_recoded$alone_mean and triplett_data_recoded$competition_mean\nt = 5.2868, df = 39, p-value = 5.048e-06\nalternative hypothesis: true mean difference is not equal to 0\n95 percent confidence interval:\n 1.277676 2.861157\nsample estimates:\nmean difference \n       2.069417 \n\n\n\n\n\n\neffectsize::cohens_d(alone_0 ~ gender, data = triplett_data)\n\n\n\n\n\nCohens_d\nCI\nCI_low\nCI_high\n\n\n\n\n0.9234365\n0.95\n0.2360446\n1.599793\n\n\n\n\n\neffectsize::cohens_d(x = triplett_data_recoded$alone_mean,\n                     y = triplett_data_recoded$competition_mean,\n                     paired = TRUE)\n\nFor paired samples, 'repeated_measures_d()' provides more options.\n\n\n\n\n\n\nCohens_d\nCI\nCI_low\nCI_high\n\n\n\n\n0.8359196\n0.95\n0.4710662\n1.192793\n\n\n\n\n\n\n\n\n\n\n\n\nThe aov() function computes an ANOVA model. It accepts a formula in the form DV ~ IV, just like the independent-samples t.test() example above.\n\n# aov expects a 'formula' in the form 'DV ~ IV'\n\naov(diff ~ classification, data = triplett_data_recoded)\n\nCall:\n   aov(formula = diff ~ classification, data = triplett_data_recoded)\n\nTerms:\n                classification Residuals\nSum of Squares       139.31890  99.69957\nDeg. of Freedom              2        37\n\nResidual standard error: 1.641518\nEstimated effects may be unbalanced\n\n\nSometimes, like with aov(), the function that computes a model doesn’t tell us everything we typically want to know about that model. It is often useful to assign the model to a name, and then ask for a summary of the model:\n\n# aov doesn't print useful output by itself, so assign to a name\n\nanova &lt;- aov(diff ~ classification, data = triplett_data_recoded)\n\n# then get a summary\n\nsummary(anova)\n\n               Df Sum Sq Mean Sq F value   Pr(&gt;F)    \nclassification  2  139.3   69.66   25.85 9.44e-08 ***\nResiduals      37   99.7    2.69                     \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\n\n\n\nThe aov() and summary() approach also works for within-participants designs. We just need to articulate the Error() term, using a column which uniquely identifies participants, and the grouping variable column.\n\n# related-samples ANOVA requires Error term, using columns\n# for participant IDs and the IV grouping variable\n\naov(performance ~ condition + Error(subject/condition), data = triplett_long) |&gt; \n  summary()\n\n\nError: subject\n          Df Sum Sq Mean Sq F value Pr(&gt;F)\ncondition  1     22   21.85   0.092  0.763\nResiduals 38   8993  236.65               \n\nError: subject:condition\n          Df Sum Sq Mean Sq F value   Pr(&gt;F)    \ncondition  1  242.2   242.2   27.84 5.22e-06 ***\nResiduals 39  339.3     8.7                     \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nError: Within\n           Df Sum Sq Mean Sq F value Pr(&gt;F)\nResiduals 161   2346   14.57               \n\n\n\n\n\n\n\n# the lm (linear model) function accepts a formula like t.test and aov\n# we can add as many predictors as we want with\n\nlm(diff ~ age + gender + group, data = triplett_data_recoded) |&gt; \n  summary()\n\n\nCall:\nlm(formula = diff ~ age + gender + group, data = triplett_data_recoded)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-3.5875 -1.7558 -0.0978  1.5994  4.9705 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)  \n(Intercept)  -5.0325     2.5089  -2.006   0.0524 .\nage           0.2385     0.2184   1.092   0.2821  \ngenderm       1.4309     0.8163   1.753   0.0881 .\ngroupB       -0.5619     0.7853  -0.716   0.4789  \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 2.398 on 36 degrees of freedom\nMultiple R-squared:  0.1342,    Adjusted R-squared:  0.06209 \nF-statistic: 1.861 on 3 and 36 DF,  p-value: 0.1537\n\n\n\n\n\n\nmixed_model &lt;- lme4::lmer(\n  performance ~ condition * age + group + (1 | subject), \n  data = triplett_long\n  )\n\nsummary(mixed_model)\n\nLinear mixed model fit by REML ['lmerMod']\nFormula: performance ~ condition * age + group + (1 | subject)\n   Data: triplett_long\n\nREML criterion at convergence: 1403\n\nScaled residuals: \n    Min      1Q  Median      3Q     Max \n-2.1757 -0.6269 -0.1108  0.4602  3.4458 \n\nRandom effects:\n Groups   Name        Variance Std.Dev.\n subject  (Intercept) 26.52    5.150   \n Residual             13.44    3.667   \nNumber of obs: 241, groups:  subject, 40\n\nFixed effects:\n                         Estimate Std. Error t value\n(Intercept)               61.8434     5.7664  10.725\nconditioncompetition      -4.6886     3.1964  -1.467\nage                       -1.9923     0.5002  -3.983\ngroupB                     1.1393     1.7148   0.664\nconditioncompetition:age   0.2287     0.2753   0.831\n\nCorrelation of Fixed Effects:\n            (Intr) cndtnc age    groupB\ncndtncmpttn -0.236                     \nage         -0.977  0.230              \ngroupB      -0.013  0.005 -0.138       \ncndtncmptt:  0.232 -0.988 -0.233  0.002\n\n\nlmr4::lmer() doesn’t give p-values (because they require some additional assumptions). The package lmerTest has wraps lmer() with some additional computation of p-values.\n\nmixed_model &lt;- lmerTest::lmer(\n  performance ~ condition * age + group + (1 | subject), \n  data = triplett_long\n  )\n\nsummary(mixed_model)\n\nLinear mixed model fit by REML. t-tests use Satterthwaite's method [\nlmerModLmerTest]\nFormula: performance ~ condition * age + group + (1 | subject)\n   Data: triplett_long\n\nREML criterion at convergence: 1403\n\nScaled residuals: \n    Min      1Q  Median      3Q     Max \n-2.1757 -0.6269 -0.1108  0.4602  3.4458 \n\nRandom effects:\n Groups   Name        Variance Std.Dev.\n subject  (Intercept) 26.52    5.150   \n Residual             13.44    3.667   \nNumber of obs: 241, groups:  subject, 40\n\nFixed effects:\n                         Estimate Std. Error       df t value Pr(&gt;|t|)    \n(Intercept)               61.8434     5.7664  41.4686  10.725 1.57e-13 ***\nconditioncompetition      -4.6886     3.1964 199.8308  -1.467  0.14399    \nage                       -1.9923     0.5002  41.3136  -3.983  0.00027 ***\ngroupB                     1.1393     1.7148  37.1406   0.664  0.51056    \nconditioncompetition:age   0.2287     0.2753 199.8510   0.831  0.40713    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nCorrelation of Fixed Effects:\n            (Intr) cndtnc age    groupB\ncndtncmpttn -0.236                     \nage         -0.977  0.230              \ngroupB      -0.013  0.005 -0.138       \ncndtncmptt:  0.232 -0.988 -0.233  0.002\n\n\n\n\n\n\nCode\ntriplett_long |&gt; \n  ggplot(aes(x = trial, y = performance, group = subject, color = condition)) +\n  geom_line(alpha = 0.3) +\n  stat_summary(aes(group = condition), fun = mean, geom = \"line\", linewidth = 1.2, color = \"black\") +\n  facet_wrap(~condition) +\n  labs(title = \"Performance over Trials by Condition\",\n       x = \"Trial\", y = \"Reeling Speed\",\n       caption = \"Color lines = individual subjects; bold line = group mean\") +\n  theme_apa\n\n\nWarning: Removed 39 rows containing non-finite outside the scale range\n(`stat_summary()`).\n\n\nWarning: Removed 19 rows containing missing values or values outside the scale range\n(`geom_line()`).",
    "crumbs": [
      "Day 1: Intro to R",
      "Working with data"
    ]
  }
]